# Gemini Live Interpreter - Technical Analysis

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [UI êµ¬ì„± ë° í™”ë©´ êµ¬ì¡°](#ui-êµ¬ì„±-ë°-í™”ë©´-êµ¬ì¡°)
4. [ìŒì„± ì „ë‹¬ ë©”ì»¤ë‹ˆì¦˜](#ìŒì„±-ì „ë‹¬-ë©”ì»¤ë‹ˆì¦˜)
5. [ë°±ì—”ë“œ í†µì‹  í”„ë¡œí† ì½œ](#ë°±ì—”ë“œ-í†µì‹ -í”„ë¡œí† ì½œ)
6. [ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ë¶„ì„](#ì£¼ìš”-ì»´í¬ë„ŒíŠ¸-ìƒì„¸-ë¶„ì„)
7. [ë°ì´í„° íë¦„ë„](#ë°ì´í„°-íë¦„ë„)
8. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)

---

## í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
**Gemini Live Interpreter**ëŠ” Googleì˜ Gemini Live APIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŒì„± í†µì—­ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ì™€ ì˜ì–´ ê°„ì˜ ì‹¤ì‹œê°„ í†µì—­ì„ ì œê³µí•˜ë©°, ì‚¬ìš©ìê°€ ë§í•œ ë‚´ìš©ì„ ì¦‰ì‹œ ìƒëŒ€ ì–¸ì–´ë¡œ ë³€í™˜í•˜ì—¬ ìŒì„±ê³¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥
- âœ… **ì‹¤ì‹œê°„ ìŒì„± ì…ë ¥**: ë§ˆì´í¬ë¥¼ í†µí•œ ì—°ì†ì ì¸ ìŒì„± ìŠ¤íŠ¸ë¦¬ë°
- âœ… **ì‹¤ì‹œê°„ ìŒì„± ì¶œë ¥**: AI í†µì—­ ê²°ê³¼ì˜ ì¦‰ê°ì ì¸ ìŒì„± ì¬ìƒ
- âœ… **ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì „ì‚¬**: ì‚¬ìš©ì ì…ë ¥ê³¼ AI ì‘ë‹µì˜ í…ìŠ¤íŠ¸ ë³€í™˜ í‘œì‹œ
- âœ… **ì˜¤ë””ì˜¤ ì‹œê°í™”**: ì…ë ¥/ì¶œë ¥ ì˜¤ë””ì˜¤ì˜ ì‹¤ì‹œê°„ íŒŒí˜• í‘œì‹œ
- âœ… **ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë°**: WebSocketì„ í†µí•œ full-duplex í†µì‹ 
- âœ… **ìŒì„± ìƒíƒœ ì¶”ì **: ë§í•˜ê¸°/ë“£ê¸°/ì²˜ë¦¬ ì¤‘ ìƒíƒœ ì‹¤ì‹œê°„ í‘œì‹œ

### ì„¤ê³„ ì˜ë„
1. **ì €ì§€ì—° í†µì‹ **: WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í†µì—­ ì§€ì—° ìµœì†Œí™”
2. **ì‚¬ìš©ì ì¹œí™”ì  UI**: ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤ë¡œ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥
3. **ì‹œê°ì  í”¼ë“œë°±**: ì˜¤ë””ì˜¤ ì‹œê°í™” ë° ìƒíƒœ í‘œì‹œë¡œ ì‹œìŠ¤í…œ ë™ì‘ íˆ¬ëª…ì„± í™•ë³´
4. **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ ì„¤ê³„ë¡œ ìœ ì§€ë³´ìˆ˜ ë° ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì¡°ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Browser (Frontend)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      App.tsx (Main)                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ WebSocket       â”‚  â”‚ Audio Input  â”‚  â”‚ Audio Output â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ Service         â”‚  â”‚ Processing   â”‚  â”‚ Playback     â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚           â”‚                   â”‚                  â”‚          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚            State Management (React Hooks)            â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚           â”‚                                                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  UI Components (Transcript, Visualizer, Controls)    â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ WebSocket (ws://)
                               â”‚ JSON + Base64 Audio
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend Server (Python)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  WebSocket Handler                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ Audio Stream    â”‚  â”‚ Gemini Live  â”‚  â”‚ Response     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ Receiver        â”‚  â”‚ API Client   â”‚  â”‚ Broadcaster  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ gRPC Streaming
                             â”‚ Bidirectional
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Google Gemini Live API                          â”‚
â”‚  â€¢ Real-time Speech Recognition (STT)                            â”‚
â”‚  â€¢ Language Translation (KO â†” EN)                                â”‚
â”‚  â€¢ Text-to-Speech Synthesis (TTS)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë ˆì´ì–´ êµ¬ì¡°

#### 1. í”„ë ˆì  í…Œì´ì…˜ ë ˆì´ì–´ (UI Components)
- **Transcript.tsx**: ëŒ€í™” ë‚´ìš© í…ìŠ¤íŠ¸ í‘œì‹œ
- **Visualizer.tsx**: ì˜¤ë””ì˜¤ íŒŒí˜• ì‹œê°í™”
- **SpeechStateIndicator.tsx**: ìŒì„± ìƒíƒœ í‘œì‹œ

#### 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆì´ì–´ (App.tsx)
- ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬
- ì˜¤ë””ì˜¤ ì…ì¶œë ¥ ì œì–´
- WebSocket ì—°ê²° ê´€ë¦¬
- ì´ë²¤íŠ¸ í•¸ë“¤ë§ ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

#### 3. ì„œë¹„ìŠ¤ ë ˆì´ì–´ (WebSocketService)
- WebSocket ì—°ê²° ìƒëª…ì£¼ê¸° ê´€ë¦¬
- ë©”ì‹œì§€ ì†¡ìˆ˜ì‹  ì²˜ë¦¬
- ìë™ ì¬ì—°ê²° ë¡œì§

#### 4. ìœ í‹¸ë¦¬í‹° ë ˆì´ì–´ (audioUtils)
- ì˜¤ë””ì˜¤ ë°ì´í„° í¬ë§· ë³€í™˜
- PCM ì¸ì½”ë”©/ë””ì½”ë”©
- Base64 ì¸ì½”ë”©/ë””ì½”ë”©

---

## UI êµ¬ì„± ë° í™”ë©´ êµ¬ì¡°

### ë ˆì´ì•„ì›ƒ êµ¬ì¡°

ì• í”Œë¦¬ì¼€ì´ì…˜ì€ **3ë‹¨ ë ˆì´ì•„ì›ƒ**ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Header (ê³ ì •)                         â”‚
â”‚  â€¢ Title: "Gemini Live Interpreter"                      â”‚
â”‚  â€¢ Language Indicator: "Korean â‡„ English"                â”‚
â”‚  â€¢ Connection Status Badge                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Left Panel (1/3)     â”‚   Right Panel (2/3)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Control Buttons  â”‚  â”‚  â”‚                           â”‚  â”‚
â”‚  â”‚ â€¢ Start/Stop     â”‚  â”‚  â”‚   Transcript Area         â”‚  â”‚
â”‚  â”‚ â€¢ Mute/Unmute    â”‚  â”‚  â”‚   (Scrollable)            â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  â”‚                           â”‚  â”‚
â”‚  â”‚ Volume Slider    â”‚  â”‚  â”‚   â€¢ User Messages         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  â”‚   â€¢ AI Messages           â”‚  â”‚
â”‚  â”‚ Speech State     â”‚  â”‚  â”‚   â€¢ Streaming Text        â”‚  â”‚
â”‚  â”‚ Indicator        â”‚  â”‚  â”‚                           â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  â”‚                           â”‚  â”‚
â”‚  â”‚ Input Visualizer â”‚  â”‚  â”‚                           â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  â”‚                           â”‚  â”‚
â”‚  â”‚ Output Visualizerâ”‚  â”‚  â”‚                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. Header (í—¤ë”)

**ìœ„ì¹˜**: í™”ë©´ ìƒë‹¨ ê³ ì • (`sticky top-0`)

**êµ¬ì„± ìš”ì†Œ**:
```tsx
<header className="px-6 py-4 border-b border-zinc-800 ...">
  {/* Left Section */}
  <div className="flex items-center gap-3">
    <div className="w-8 h-8 rounded-lg bg-blue-600">
      <Settings2 /> {/* Logo Icon */}
    </div>
    <div>
      <h1>Gemini Live Interpreter</h1>
      <p>Korean â‡„ English</p>
    </div>
  </div>

  {/* Right Section */}
  <div className="flex items-center gap-4">
    <ConnectionStatusBadge /> {/* CONNECTED/CONNECTING/DISCONNECTED */}
  </div>
</header>
```

**ê¸°ëŠ¥**:
- ì• í”Œë¦¬ì¼€ì´ì…˜ ë¸Œëœë”© í‘œì‹œ
- ì§€ì› ì–¸ì–´ ìŒ ëª…ì‹œ (í•œêµ­ì–´ â‡„ ì˜ì–´)
- ì‹¤ì‹œê°„ ì—°ê²° ìƒíƒœ í‘œì‹œ (ì´ˆë¡ìƒ‰: ì—°ê²°ë¨, ë…¸ë€ìƒ‰: ì—°ê²° ì¤‘, íšŒìƒ‰: ì—°ê²° ëŠê¹€)

### 2. Left Panel (ì¢Œì¸¡ ì œì–´ íŒ¨ë„)

**ìœ„ì¹˜**: ë°ìŠ¤í¬í†±ì—ì„œ í™”ë©´ ì™¼ìª½ 1/3, ëª¨ë°”ì¼ì—ì„œ ìƒë‹¨

**êµ¬ì„± ìš”ì†Œ**:

#### A. Control Center (ì œì–´ ì„¼í„°)
```tsx
<div className="grid grid-cols-2 gap-3">
  {/* Start/Stop Session Button */}
  <button onClick={toggle}>
    <Power />
    {connected ? 'Stop Session' : 'Start Session'}
  </button>

  {/* Mute/Unmute Button */}
  <button onClick={toggleMute}>
    {isMuted ? <MicOff /> : <Mic />}
    {isMuted ? 'Unmute Mic' : 'Mute Mic'}
  </button>
</div>
```

**ê¸°ëŠ¥**:
- **Start/Stop Session**: WebSocket ì—°ê²° ë° ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘/ì¢…ë£Œ
- **Mute/Unmute Mic**: ë§ˆì´í¬ ìŒì†Œê±° í† ê¸€ (ì—°ê²° ì¤‘ì—ë§Œ í™œì„±í™”)

#### B. Volume Slider (ë³¼ë¥¨ ì¡°ì ˆ)
```tsx
<input
  type="range"
  min="0"
  max="1.5"
  step="0.05"
  value={volume}
  onChange={handleVolumeChange}
/>
```

**ê¸°ëŠ¥**:
- AI ì‘ë‹µ ìŒì„± ì¶œë ¥ ë³¼ë¥¨ ì‹¤ì‹œê°„ ì¡°ì ˆ (0% ~ 150%)
- ì¦‰ê° ë°˜ì˜ (GainNodeë¥¼ í†µí•œ ì˜¤ë””ì˜¤ ì¦í­ ì œì–´)

#### C. Speech State Indicator (ìŒì„± ìƒíƒœ í‘œì‹œ)
```tsx
<SpeechStateIndicator state={speechState} />
```

**3ê°€ì§€ ìƒíƒœ**:
- ğŸ¤ **Speaking** (ë§ì”€í•˜ì„¸ìš”...): ì‚¬ìš©ìê°€ ë§í•  ìˆ˜ ìˆëŠ” ìƒíƒœ
- ğŸ‘‚ **Silent** (ë“£ê³  ìˆìŠµë‹ˆë‹¤...): AIê°€ ì‘ë‹µ ì¤‘ì´ê±°ë‚˜ ëŒ€ê¸° ì¤‘
- â³ **Processing** (ì²˜ë¦¬ ì¤‘...): AIê°€ ì…ë ¥ì„ ë¶„ì„í•˜ëŠ” ì¤‘

#### D. Audio Visualizers (ì˜¤ë””ì˜¤ ì‹œê°í™”)

**Input Visualizer** (ì‚¬ìš©ì ì…ë ¥):
```tsx
<Visualizer
  analyser={inputAnalyserState}
  isActive={connected && !isMuted}
  color="#a1a1aa" // íšŒìƒ‰
/>
```

**Output Visualizer** (AI ì¶œë ¥):
```tsx
<Visualizer
  analyser={outputAnalyserState}
  isActive={connected}
  color="#3b82f6" // íŒŒë€ìƒ‰
/>
```

**ì‹œê°í™” ì›ë¦¬**:
- Web Audio APIì˜ `AnalyserNode` ì‚¬ìš©
- `getByteTimeDomainData()`ë¡œ ì‹œê°„ ë„ë©”ì¸ ë°ì´í„° ì¶”ì¶œ
- Canvas APIë¡œ ì‹¤ì‹œê°„ íŒŒí˜• ë Œë”ë§ (60fps)
- ì—°ê²° í•´ì œ ì‹œ í‰í‰í•œ ì„  í‘œì‹œ

### 3. Right Panel (ìš°ì¸¡ ëŒ€í™” íŒ¨ë„)

**ìœ„ì¹˜**: ë°ìŠ¤í¬í†±ì—ì„œ í™”ë©´ ì˜¤ë¥¸ìª½ 2/3, ëª¨ë°”ì¼ì—ì„œ í•˜ë‹¨

**êµ¬ì„± ìš”ì†Œ**:

#### Transcript Component (ëŒ€í™” ë‚´ìš©)

```tsx
<Transcript
  messages={messages}          // í™•ì •ëœ ë©”ì‹œì§€ ëª©ë¡
  userText={streamingUserText} // ì‹¤ì‹œê°„ ì‚¬ìš©ì ì…ë ¥ (ì„ì‹œ)
  modelText={streamingModelText} // ì‹¤ì‹œê°„ AI ì‘ë‹µ (ì„ì‹œ)
/>
```

**ë©”ì‹œì§€ í‘œì‹œ ë°©ì‹**:

1. **ì‚¬ìš©ì ë©”ì‹œì§€** (ìš°ì¸¡ ì •ë ¬):
```tsx
<div className="flex gap-3 justify-end">
  <div className="bg-zinc-800 text-zinc-100 rounded-2xl rounded-tr-sm">
    {msg.text}
  </div>
  <User icon /> {/* íšŒìƒ‰ ì•„ì´ì½˜ */}
</div>
```

2. **AI ë©”ì‹œì§€** (ì¢Œì¸¡ ì •ë ¬):
```tsx
<div className="flex gap-3 justify-start">
  <Bot icon /> {/* íŒŒë€ìƒ‰ ì•„ì´ì½˜ */}
  <div className="bg-blue-950/40 border border-blue-900/50 text-blue-100 rounded-2xl rounded-tl-sm">
    {msg.text}
  </div>
</div>
```

3. **ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ í…ìŠ¤íŠ¸** (ë°˜íˆ¬ëª… + ê¹œë¹¡ì´ëŠ” ì»¤ì„œ):
```tsx
{userText.trim() && (
  <div className="opacity-80 bg-zinc-800/80">
    {userText}
    <span className="animate-pulse">|</span> {/* íƒ€ì´í•‘ ì»¤ì„œ */}
  </div>
)}
```

**ìë™ ìŠ¤í¬ë¡¤**:
```tsx
useEffect(() => {
  bottomRef.current?.scrollIntoView({ behavior: 'smooth' });
}, [messages, userText, modelText]);
```
- ìƒˆë¡œìš´ ë©”ì‹œì§€ë‚˜ ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ê°€ ì—…ë°ì´íŠ¸ë  ë•Œë§ˆë‹¤ ìë™ìœ¼ë¡œ í•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤

**ë¹ˆ í™”ë©´ í‘œì‹œ**:
```tsx
{messages.length === 0 && !userText && !modelText && (
  <div className="flex flex-col items-center justify-center">
    <Bot className="w-12 h-12" />
    <p>Ready to interpret.</p>
    <p>Speak Korean or English.</p>
  </div>
)}
```

### ìƒ‰ìƒ ë° ë””ìì¸ ì‹œìŠ¤í…œ

**í…Œë§ˆ**: Dark Mode (Zinc/Blue Palette)

**ì£¼ìš” ìƒ‰ìƒ**:
- ë°°ê²½: `bg-zinc-950` (ê±°ì˜ ê²€ì •)
- íŒ¨ë„: `bg-zinc-900` (ì–´ë‘ìš´ íšŒìƒ‰)
- ì‚¬ìš©ì ë©”ì‹œì§€: `bg-zinc-800` (ì¤‘ê°„ íšŒìƒ‰)
- AI ë©”ì‹œì§€: `bg-blue-950/40` (ë°˜íˆ¬ëª… íŒŒë‘)
- ê°•ì¡° ìƒ‰ìƒ: `text-blue-400`, `border-blue-500`

**ì‹œê°ì  í”¼ë“œë°±**:
- ì—°ê²° ìƒíƒœ: ì´ˆë¡ìƒ‰(ì—°ê²°)/ë…¸ë€ìƒ‰(ì—°ê²° ì¤‘)/íšŒìƒ‰(ì—°ê²° ëŠê¹€)
- ìŒì„± ìƒíƒœ: ì´ˆë¡ìƒ‰(speaking)/íšŒìƒ‰(silent)/íŒŒë€ìƒ‰(processing)
- ì• ë‹ˆë©”ì´ì…˜: `animate-pulse` (ìƒíƒœ í‘œì‹œ), `animate-spin-slow` (ì²˜ë¦¬ ì¤‘)

---

## ìŒì„± ì „ë‹¬ ë©”ì»¤ë‹ˆì¦˜

### ìŒì„± ì…ë ¥ ì²˜ë¦¬ Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Microphone   â”‚
â”‚ (Hardware)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ getUserMedia()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MediaStream                         â”‚
â”‚  (Raw Audio from Browser)            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MediaStreamAudioSourceNode          â”‚
â”‚  (Web Audio API Input)               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AnalyserNode   â”‚  â”‚ ScriptProcessor â”‚
â”‚  (Visualization)â”‚  â”‚  Node (Audio    â”‚
â”‚                 â”‚  â”‚   Processing)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ onaudioprocess event
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Float32Array     â”‚
                     â”‚ (4096 samples)   â”‚
                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ floatTo16BitPCM()
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Int16 PCM        â”‚
                     â”‚ (16-bit audio)   â”‚
                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ arrayBufferToBase64()
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Base64 String    â”‚
                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ WebSocket.send()
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Backend Server   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìƒì„¸ êµ¬í˜„

#### 1. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”

```tsx
// App.tsx: connectToBackend() í•¨ìˆ˜ ë‚´ë¶€

// 1. AudioContext ìƒì„± (16kHz ìƒ˜í”Œë ˆì´íŠ¸)
const inputCtx = new AudioContext({ sampleRate: PCM_SAMPLE_RATE }); // 16000Hz

// 2. ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­ ë° ìŠ¤íŠ¸ë¦¼ íšë“
const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

// 3. MediaStreamSource ìƒì„±
const source = inputCtx.createMediaStreamSource(stream);
sourceNodeRef.current = source;
```

**ì¤‘ìš”**: Gemini Live APIëŠ” **16kHz PCM ì˜¤ë””ì˜¤**ë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ AudioContextë¥¼ 16000Hzë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

#### 2. ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì²´ì¸ êµ¬ì„±

```tsx
// Visualizerìš© Analyser ë…¸ë“œ
const inAnalyser = inputCtx.createAnalyser();
inAnalyser.fftSize = 256;
source.connect(inAnalyser);

// ì˜¤ë””ì˜¤ ì²˜ë¦¬ìš© ScriptProcessor ë…¸ë“œ
const processor = inputCtx.createScriptProcessor(4096, 1, 1);
// íŒŒë¼ë¯¸í„°: bufferSize=4096, inputChannels=1, outputChannels=1

processor.onaudioprocess = (e) => {
  if (isMutedRef.current) return; // ìŒì†Œê±° ì‹œ ìŠ¤í‚µ

  const inputData = e.inputBuffer.getChannelData(0); // Float32Array
  const packet = createPcmBlob(inputData);

  // WebSocketìœ¼ë¡œ ì „ì†¡
  wsServiceRef.current?.sendAudioData(packet.data, Date.now());
};

source.connect(processor);
processor.connect(inputCtx.destination); // í•„ìˆ˜: ë…¸ë“œ í™œì„±í™”
```

**ScriptProcessorNode ì„ íƒ ì´ìœ **:
- `AudioWorklet`ì€ ë” í˜„ëŒ€ì ì´ì§€ë§Œ ë¸Œë¼ìš°ì € ì§€ì›ì´ ì œí•œì 
- `ScriptProcessorNode`ëŠ” deprecatedë˜ì—ˆì§€ë§Œ ê´‘ë²”ìœ„í•œ ë¸Œë¼ìš°ì € ì§€ì›
- 4096 ë²„í¼ í¬ê¸°ëŠ” ì§€ì—°ê³¼ ì„±ëŠ¥ì˜ ê· í˜•ì 

#### 3. ì˜¤ë””ì˜¤ ë°ì´í„° ë³€í™˜ (audioUtils.ts)

```tsx
// Float32 â†’ Int16 PCM ë³€í™˜
export function floatTo16BitPCM(float32Array: Float32Array): ArrayBuffer {
  const buffer = new ArrayBuffer(float32Array.length * 2); // 2 bytes per sample
  const view = new DataView(buffer);

  for (let i = 0; i < float32Array.length; i++) {
    // 1. Float32 ê°’ í´ë¨í•‘ (-1.0 ~ 1.0)
    let s = Math.max(-1, Math.min(1, float32Array[i]));

    // 2. Int16 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
    s = s < 0 ? s * 0x8000 : s * 0x7fff; // -32768 ~ 32767

    // 3. Little-endianìœ¼ë¡œ ì €ì¥
    view.setInt16(i * 2, s, true);
  }

  return buffer;
}

// ArrayBuffer â†’ Base64 ì¸ì½”ë”©
export function arrayBufferToBase64(buffer: ArrayBuffer): string {
  let binary = '';
  const bytes = new Uint8Array(buffer);
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

// ìµœì¢… íŒ¨í‚· ìƒì„±
export function createPcmBlob(data: Float32Array): PcmBlob {
  const pcmData = floatTo16BitPCM(data);
  const base64 = arrayBufferToBase64(pcmData);

  return {
    data: base64,
    mimeType: `audio/pcm;rate=${PCM_SAMPLE_RATE}`, // "audio/pcm;rate=16000"
  };
}
```

**ë³€í™˜ ê³¼ì •**:
1. **Float32Array** (Web Audio API ê¸°ë³¸ í¬ë§·, -1.0 ~ 1.0)
2. **Int16 PCM** (Gemini API ìš”êµ¬ì‚¬í•­, -32768 ~ 32767)
3. **Base64 String** (WebSocket ì „ì†¡ìš© í…ìŠ¤íŠ¸ ì¸ì½”ë”©)

#### 4. WebSocket ì „ì†¡

```tsx
// WebSocketService.ts
sendAudioData(base64Data: string, timestamp: number) {
  this.send({
    type: 'audio',
    data: base64Data,
    timestamp
  });
}

send(data: Record<string, unknown>) {
  if (this.ws && this.ws.readyState === WebSocket.OPEN) {
    this.ws.send(JSON.stringify(data));
  }
}
```

**ì „ì†¡ ë©”ì‹œì§€ í˜•ì‹**:
```json
{
  "type": "audio",
  "data": "AAABAAACAAA...", // Base64 encoded PCM
  "timestamp": 1234567890123
}
```

**ì „ì†¡ ì£¼ê¸°**:
- ë²„í¼ í¬ê¸°: 4096 samples
- ìƒ˜í”Œë ˆì´íŠ¸: 16000 Hz
- ì „ì†¡ ì£¼ê¸°: 4096 / 16000 = **256msë§ˆë‹¤**

### ìŒì„± ì¶œë ¥ ì²˜ë¦¬ Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend Server   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ WebSocket Message
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ { type: 'audio_response',          â”‚
â”‚   data: "base64...",               â”‚
â”‚   sampleRate: 24000 }              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ handleWebSocketMessage()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Base64 String    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ base64ToArrayBuffer()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ArrayBuffer      â”‚
â”‚ (PCM Int16)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ decodeAudioData()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AudioBuffer                      â”‚
â”‚ (Float32, 24kHz, 1 channel)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ createBufferSource()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AudioBufferSourceNode            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ connect()
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GainNode         â”‚ â† Volume Control
â”‚ (volume)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AnalyserNode    â”‚  â”‚ Destination     â”‚
â”‚ (Visualization) â”‚  â”‚ (Speaker)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìƒì„¸ êµ¬í˜„

#### 1. ì¶œë ¥ AudioContext ì´ˆê¸°í™”

```tsx
// App.tsx: connectToBackend()

// 24kHz AudioContext (Gemini ëª¨ë¸ ì¶œë ¥ ìƒ˜í”Œë ˆì´íŠ¸)
const outputCtx = new AudioContext({ sampleRate: 24000 });
outputAudioContextRef.current = outputCtx;

// GainNodeë¡œ ë³¼ë¥¨ ì œì–´
const outGain = outputCtx.createGain();
outGain.gain.value = volume; // 0.0 ~ 1.5
outGain.connect(outputCtx.destination);
outputGainRef.current = outGain;

// Visualizerìš© Analyser
const outAnalyser = outputCtx.createAnalyser();
outAnalyser.fftSize = 256;
outGain.connect(outAnalyser);
```

#### 2. WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  ë° ë””ì½”ë”©

```tsx
// App.tsx: handleWebSocketMessage()

case 'audio_response':
  if (message.data && outputAudioContextRef.current) {
    const ctx = outputAudioContextRef.current;

    // 1. Base64 â†’ ArrayBuffer
    const arrayBuffer = base64ToArrayBuffer(message.data);

    // 2. PCM Int16 â†’ AudioBuffer
    const audioBuffer = await decodeAudioData(arrayBuffer, ctx);

    // 3. ì¬ìƒ ìŠ¤ì¼€ì¤„ë§
    playAudioBuffer(audioBuffer);
  }
  break;
```

#### 3. PCM ìˆ˜ë™ ë””ì½”ë”© (audioUtils.ts)

```tsx
export async function decodeAudioData(
  arrayBuffer: ArrayBuffer,
  ctx: AudioContext
): Promise<AudioBuffer> {
  // GeminiëŠ” raw PCM 16-bit little-endianì„ ë°˜í™˜
  const dataInt16 = new Int16Array(arrayBuffer);
  const numChannels = 1; // Mono
  const frameCount = dataInt16.length / numChannels;

  // AudioBuffer ìƒì„±
  const audioBuffer = ctx.createBuffer(
    numChannels,
    frameCount,
    24000 // OUTPUT_SAMPLE_RATE
  );

  // Int16 â†’ Float32 ë³€í™˜ ë° ë³µì‚¬
  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = audioBuffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      // Int16 (-32768 ~ 32767) â†’ Float32 (-1.0 ~ 1.0)
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }

  return audioBuffer;
}
```

**ìˆ˜ë™ ë””ì½”ë”© ì´ìœ **:
- Gemini APIëŠ” **í—¤ë” ì—†ëŠ” raw PCM ë°ì´í„°**ë¥¼ ë°˜í™˜
- `AudioContext.decodeAudioData()`ëŠ” **WAV/MP3 ë“± í—¤ë” í¬í•¨ í¬ë§·**ë§Œ ì§€ì›
- ë”°ë¼ì„œ Int16 â†’ Float32 ë³€í™˜ì„ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜í–‰

#### 4. ì˜¤ë””ì˜¤ ì¬ìƒ íì‰ ì‹œìŠ¤í…œ

```tsx
// App.tsx

// ì¬ìƒ í ê´€ë¦¬
const nextStartTimeRef = useRef<number>(0);
const activeSourcesRef = useRef<Set<AudioBufferSourceNode>>(new Set());

const playAudioBuffer = (buffer: AudioBuffer) => {
  const ctx = outputAudioContextRef.current!;

  // 1. ë‹¤ìŒ ì¬ìƒ ì‹œì‘ ì‹œê°„ ê³„ì‚° (ëŠê¹€ ì—†ëŠ” ì—°ì† ì¬ìƒ)
  nextStartTimeRef.current = Math.max(
    nextStartTimeRef.current,
    ctx.currentTime
  );

  // 2. BufferSource ìƒì„± ë° ì—°ê²°
  const source = ctx.createBufferSource();
  source.buffer = buffer;
  source.connect(outputGainRef.current!);

  // 3. ìŠ¤ì¼€ì¤„ë§ëœ ì‹œê°„ì— ì¬ìƒ ì‹œì‘
  source.start(nextStartTimeRef.current);

  // 4. ë‹¤ìŒ ì²­í¬ë¥¼ ìœ„í•œ ì‹œê°„ ì—…ë°ì´íŠ¸
  nextStartTimeRef.current += buffer.duration;

  // 5. í™œì„± ì†ŒìŠ¤ ì¶”ì 
  activeSourcesRef.current.add(source);
  source.onended = () => activeSourcesRef.current.delete(source);
};
```

**íì‰ ì‹œìŠ¤í…œì˜ ì¤‘ìš”ì„±**:
- WebSocketì€ ì˜¤ë””ì˜¤ë¥¼ **ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í•  ì „ì†¡**
- ê° ì²­í¬ë¥¼ ì¦‰ì‹œ ì¬ìƒí•˜ë©´ **ëŠê¹€ í˜„ìƒ** ë°œìƒ
- `nextStartTime`ìœ¼ë¡œ ì²­í¬ë¥¼ **ì—°ì†ì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë§**í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì¬ìƒ

**ì˜ˆì‹œ**:
```
currentTime = 0.0s
Chunk 1 ë„ì°© â†’ start(0.0), duration=0.5s â†’ nextStartTime = 0.5s
Chunk 2 ë„ì°© â†’ start(0.5), duration=0.3s â†’ nextStartTime = 0.8s
Chunk 3 ë„ì°© â†’ start(0.8), duration=0.4s â†’ nextStartTime = 1.2s
```

### ìŒì„± ì‹œê°í™” (Visualizer)

```tsx
// Visualizer.tsx

const render = () => {
  if (!isActive || !analyser) {
    // ë¹„í™œì„± ì‹œ í‰í‰í•œ ì„  í‘œì‹œ
    ctx.beginPath();
    ctx.moveTo(0, height / 2);
    ctx.lineTo(width, height / 2);
    ctx.strokeStyle = '#27272a';
    ctx.stroke();
    return;
  }

  // 1. ì‹œê°„ ë„ë©”ì¸ ë°ì´í„° ì¶”ì¶œ (íŒŒí˜•)
  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);
  analyser.getByteTimeDomainData(dataArray);

  // 2. Canvasì— íŒŒí˜• ê·¸ë¦¬ê¸°
  ctx.lineWidth = 3;
  ctx.strokeStyle = color;
  ctx.beginPath();

  const sliceWidth = width / bufferLength;
  let x = 0;

  for (let i = 0; i < bufferLength; i++) {
    const v = dataArray[i] / 128.0; // 0 ~ 2.0 ë²”ìœ„
    const y = v * height / 2;

    if (i === 0) {
      ctx.moveTo(x, y);
    } else {
      ctx.lineTo(x, y);
    }
    x += sliceWidth;
  }

  ctx.stroke();

  // 3. ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ ìš”ì²­ (60fps)
  requestAnimationFrame(render);
};
```

**ì‹œê°í™” ì›ë¦¬**:
- `AnalyserNode.getByteTimeDomainData()`: í˜„ì¬ ì˜¤ë””ì˜¤ íŒŒí˜•ì„ 256ê°œ ìƒ˜í”Œë¡œ ìŠ¤ëƒ…ìƒ·
- ê° ìƒ˜í”Œì„ Canvasì˜ Yì¢Œí‘œë¡œ ë³€í™˜í•˜ì—¬ ì—°ê²°
- 60fpsë¡œ ì§€ì†ì ìœ¼ë¡œ ë Œë”ë§í•˜ì—¬ ì‹¤ì‹œê°„ íŒŒí˜• ì• ë‹ˆë©”ì´ì…˜ êµ¬í˜„

---

## ë°±ì—”ë“œ í†µì‹  í”„ë¡œí† ì½œ

### WebSocket ì—°ê²° ìƒëª…ì£¼ê¸°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. Connect
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ new WebSocket(wsUrl)             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. onopen event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Send: { type: 'init', config }   â”‚
â”‚       config: {                  â”‚
â”‚         language: 'auto',        â”‚
â”‚         useWhisper: false,       â”‚
â”‚         sampleRate: 16000        â”‚
â”‚       }                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. Receive
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ { type: 'connected',             â”‚
â”‚   sessionId: "uuid..." }         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. Bidirectional Streaming
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Send Audio  â”‚ â”‚ Receive  â”‚ â”‚ Receive      â”‚
â”‚ Chunks      â”‚ â”‚ Transcripâ”‚ â”‚ Audio        â”‚
â”‚ (256ms)     â”‚ â”‚ tion     â”‚ â”‚ Response     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚
       â”‚ 5. User Disconnects or Error
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Send: { type: 'close' }          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. onclose event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cleanup & Reconnect Logic        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ

#### 1. í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„ ë©”ì‹œì§€

##### A. ì´ˆê¸°í™” ë©”ì‹œì§€
```json
{
  "type": "init",
  "config": {
    "language": "auto",      // ìë™ ì–¸ì–´ ê°ì§€
    "useWhisper": false,     // Gemini STT ì‚¬ìš© (Whisper ë¯¸ì‚¬ìš©)
    "sampleRate": 16000      // 16kHz PCM
  }
}
```

**ëª©ì **: WebSocket ì—°ê²° í›„ ì„¸ì…˜ ì´ˆê¸°í™” ë° ì„¤ì • ì „ë‹¬

##### B. ì˜¤ë””ì˜¤ ë°ì´í„° ë©”ì‹œì§€
```json
{
  "type": "audio",
  "data": "AAABAAACAAAD...",  // Base64 encoded PCM Int16
  "timestamp": 1234567890123  // í´ë¼ì´ì–¸íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„
}
```

**ëª©ì **: ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° (256msë§ˆë‹¤ ì „ì†¡)

**ì „ì†¡ ì½”ë“œ**:
```tsx
// WebSocketService.ts
sendAudioData(base64Data: string, timestamp: number) {
  this.send({ type: 'audio', data: base64Data, timestamp });
}
```

##### C. ì¤‘ë‹¨ ë©”ì‹œì§€
```json
{
  "type": "interrupt"
}
```

**ëª©ì **: AI ì‘ë‹µ ì¤‘ë‹¨ ìš”ì²­ (í˜„ì¬ ë¯¸êµ¬í˜„, í–¥í›„ í™•ì¥ ê°€ëŠ¥)

##### D. ì¢…ë£Œ ë©”ì‹œì§€
```json
{
  "type": "close"
}
```

**ëª©ì **: ì •ìƒ ì¢…ë£Œ ì‹œ ì„œë²„ì— ì•Œë¦¼

#### 2. ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€

##### A. ì—°ê²° í™•ì¸ ë©”ì‹œì§€
```json
{
  "type": "connected",
  "sessionId": "550e8400-e29b-41d4-a716-446655440000"
}
```

**ì²˜ë¦¬**:
```tsx
case 'connected':
  setConnectionState(ConnectionState.CONNECTED);
  setError(null);
  break;
```

##### B. ì…ë ¥ ì „ì‚¬ ë©”ì‹œì§€ (ì‚¬ìš©ì ìŒì„± â†’ í…ìŠ¤íŠ¸)
```json
{
  "type": "input_transcription",
  "text": "ì•ˆë…•í•˜ì„¸ìš”",
  "isFinal": false,        // ìŠ¤íŠ¸ë¦¬ë° ì¤‘
  "language": "ko"
}
```

```json
{
  "type": "input_transcription",
  "text": "ì•ˆë…•í•˜ì„¸ìš”",
  "isFinal": true,         // ìµœì¢… í™•ì •
  "language": "ko"
}
```

**ì²˜ë¦¬**:
```tsx
case 'input_transcription':
  if (message.isFinal) {
    commitMessage('user', message.text); // ë©”ì‹œì§€ ëª©ë¡ì— ì¶”ê°€
    setStreamingUserText('');            // ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
  } else {
    setStreamingUserText(message.text);  // ì‹¤ì‹œê°„ í‘œì‹œ
  }
  break;
```

##### C. ì¶œë ¥ ì „ì‚¬ ë©”ì‹œì§€ (AI ì‘ë‹µ í…ìŠ¤íŠ¸)
```json
{
  "type": "output_transcription",
  "text": "Hello",
  "isFinal": false,
  "language": "en"
}
```

**ì²˜ë¦¬**: ì…ë ¥ ì „ì‚¬ì™€ ë™ì¼í•œ íŒ¨í„´

##### D. ì˜¤ë””ì˜¤ ì‘ë‹µ ë©”ì‹œì§€ (AI ì‘ë‹µ ìŒì„±)
```json
{
  "type": "audio_response",
  "data": "AAABAAACAAAD...",  // Base64 encoded PCM Int16
  "sampleRate": 24000         // 24kHz (Gemini ì¶œë ¥ ìƒ˜í”Œë ˆì´íŠ¸)
}
```

**ì²˜ë¦¬**:
```tsx
case 'audio_response':
  if (message.data && outputAudioContextRef.current) {
    const ctx = outputAudioContextRef.current;
    nextStartTimeRef.current = Math.max(
      nextStartTimeRef.current,
      ctx.currentTime
    );

    decodeAudioData(base64ToArrayBuffer(message.data), ctx)
      .then(buffer => {
        const source = ctx.createBufferSource();
        source.buffer = buffer;
        source.connect(outputGainRef.current!);
        source.start(nextStartTimeRef.current);
        nextStartTimeRef.current += buffer.duration;
        activeSourcesRef.current.add(source);
        source.onended = () => activeSourcesRef.current.delete(source);
      })
      .catch(err => console.error('Audio decode error', err));
  }
  break;
```

##### E. í„´ ì™„ë£Œ ë©”ì‹œì§€
```json
{
  "type": "turn_complete",
  "inputText": "ì•ˆë…•í•˜ì„¸ìš”",
  "outputText": "Hello"
}
```

**ëª©ì **: í•œ ë²ˆì˜ ëŒ€í™” í„´ì´ ì™„ë£Œë˜ì—ˆìŒì„ ì•Œë¦¼

**ì²˜ë¦¬**:
```tsx
case 'turn_complete':
  setStreamingUserText('');
  setStreamingModelText('');
  // ì²« í„´ ì™„ë£Œ ì¶”ì  (2ë²ˆì§¸ ìŒì„± ë¡œê¹…ìš©)
  if (!firstTurnCompletedRef.current) {
    firstTurnCompletedRef.current = true;
    secondSpeechLoggedRef.current = false;
  }
  break;
```

##### F. ìŒì„± ìƒíƒœ ë©”ì‹œì§€
```json
{
  "type": "speech_state",
  "state": "speaking",      // "speaking" | "silent" | "processing"
  "timestamp": 1234567890123
}
```

**ì²˜ë¦¬**:
```tsx
case 'speech_state':
  setSpeechState(message.state);
  break;
```

**ìƒíƒœ ì˜ë¯¸**:
- `speaking`: ì‚¬ìš©ìê°€ ë§í•  ìˆ˜ ìˆëŠ” ìƒíƒœ
- `silent`: ëŒ€ê¸° ì¤‘ ë˜ëŠ” AI ì‘ë‹µ ì¤‘
- `processing`: AIê°€ ì…ë ¥ì„ ë¶„ì„í•˜ëŠ” ì¤‘

##### G. ì—ëŸ¬ ë©”ì‹œì§€
```json
{
  "type": "error",
  "message": "Connection error",
  "code": "CONN_ERROR"
}
```

**ì²˜ë¦¬**:
```tsx
case 'error':
  setError(message.message || 'WebSocket error');
  setConnectionState(ConnectionState.ERROR);
  break;
```

### WebSocket ì¬ì—°ê²° ë¡œì§

```tsx
// WebSocketService.ts

private scheduleReconnect() {
  if (!this.initConfig) return;

  // ìµœëŒ€ ì¬ì—°ê²° ì‹œë„ íšŸìˆ˜ ì²´í¬
  if (this.reconnectAttempts >= this.maxReconnectAttempts) {
    this.callbacks.onError(new Event('Maximum reconnect attempts reached'));
    return;
  }

  // ì¬ì—°ê²° ì‹œë„ íšŸìˆ˜ ì¦ê°€
  this.reconnectAttempts += 1;

  // Exponential backoff: 2ì´ˆ * ì‹œë„ íšŸìˆ˜
  const delay = 2000 * this.reconnectAttempts;

  this.clearReconnectTimer();
  this.reconnectTimer = window.setTimeout(() => {
    if (!this.initConfig) return;
    this.connect(this.initConfig); // ì¬ì—°ê²° ì‹œë„
  }, delay);
}
```

**ì¬ì—°ê²° ì •ì±…**:
- 1ì°¨ ì‹œë„: 2ì´ˆ í›„
- 2ì°¨ ì‹œë„: 4ì´ˆ í›„
- 3ì°¨ ì‹œë„: 6ì´ˆ í›„
- 4ì°¨ ì‹œë„: 8ì´ˆ í›„
- 5ì°¨ ì‹œë„: 10ì´ˆ í›„
- 5íšŒ ì‹¤íŒ¨ ì‹œ ì¬ì—°ê²° í¬ê¸°

**ì¬ì—°ê²° í”Œë¡œìš°**:
```
WebSocket Close
      â”‚
      â–¼
  shouldReconnect? â”€â”€â”€â”€Noâ”€â”€â”€â–º End
      â”‚
     Yes
      â–¼
  attempts < 5? â”€â”€â”€â”€Noâ”€â”€â”€â–º Emit Error
      â”‚
     Yes
      â–¼
  delay = 2s * attempts
      â”‚
      â–¼
  setTimeout(connect, delay)
      â”‚
      â–¼
  Retry Connection
```

### ì „ì²´ í†µì‹  ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

```
Frontend                WebSocket               Backend                Gemini API
   â”‚                       â”‚                       â”‚                       â”‚
   â”‚â”€â”€â”€â”€â”€Connect()â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                       â”‚                       â”‚
   â”‚                       â”‚â”€â”€â”€â”€onopenâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                       â”‚
   â”‚                       â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚<â”€â”€â”€â”€onopen eventâ”€â”€â”€â”€â”€â”€â”‚                       â”‚                       â”‚
   â”‚                       â”‚                       â”‚                       â”‚
   â”‚â”€â”€Send {type:init}â”€â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€Connect()â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚                       â”‚                       â”‚<â”€â”€â”€â”€â”€Session IDâ”€â”€â”€â”€â”€â”€â”€â”‚
   â”‚<â”€{type:connected}â”€â”€â”€â”€â”€â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚                       â”‚                       â”‚                       â”‚
   â”‚â”€â”€Send {audio:data}â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€Stream Audioâ”€â”€â”€â”€>â”‚
   â”‚â”€â”€Send {audio:data}â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€Stream Audioâ”€â”€â”€â”€>â”‚
   â”‚                       â”‚                       â”‚<â”€â”€â”€â”€â”€STT Resultâ”€â”€â”€â”€â”€â”€â”€â”‚
   â”‚<â”€{input_transcription}â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚                       â”‚                       â”‚<â”€â”€â”€â”€â”€Translationâ”€â”€â”€â”€â”€â”€â”‚
   â”‚<â”€{output_transcriptionâ”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚                       â”‚                       â”‚<â”€â”€â”€â”€â”€TTS Audioâ”€â”€â”€â”€â”€â”€â”€â”€â”‚
   â”‚<â”€{audio_response}â”€â”€â”€â”€â”€â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚<â”€{audio_response}â”€â”€â”€â”€â”€â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚                       â”‚                       â”‚<â”€â”€â”€â”€â”€Turn Completeâ”€â”€â”€â”€â”‚
   â”‚<â”€{turn_complete}â”€â”€â”€â”€â”€â”€â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                       â”‚
   â”‚                       â”‚                       â”‚                       â”‚
   â”‚â”€â”€Send {type:close}â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚â”€â”€â”€â”€â”€â”€Disconnect()â”€â”€â”€â”€>â”‚
   â”‚                       â”‚â”€â”€â”€â”€oncloseâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                       â”‚
   â”‚<â”€â”€â”€â”€onclose eventâ”€â”€â”€â”€â”€â”‚                       â”‚                       â”‚
```

---

## ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ë¶„ì„

### 1. App.tsx (ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜)

**ì—­í• **: ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°

#### ìƒíƒœ ê´€ë¦¬ (React Hooks)

```tsx
// ì—°ê²° ìƒíƒœ
const [connectionState, setConnectionState] = useState<ConnectionState>(
  ConnectionState.DISCONNECTED
);

// ë©”ì‹œì§€ ëª©ë¡ (í™•ì •ëœ ëŒ€í™” ë‚´ìš©)
const [messages, setMessages] = useState<ChatMessage[]>([]);

// ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ í…ìŠ¤íŠ¸ (ì„ì‹œ)
const [streamingUserText, setStreamingUserText] = useState<string>('');
const [streamingModelText, setStreamingModelText] = useState<string>('');

// UI ì œì–´
const [error, setError] = useState<string | null>(null);
const [isMuted, setIsMuted] = useState(false);
const [volume, setVolume] = useState(1.0);
const [speechState, setSpeechState] = useState<SpeechState>('silent');
```

#### Refs (ë³€ê²½ ê°€ëŠ¥í•œ ì°¸ì¡°)

```tsx
// Audio ì²˜ë¦¬
const inputAudioContextRef = useRef<AudioContext | null>(null);
const outputAudioContextRef = useRef<AudioContext | null>(null);
const scriptProcessorRef = useRef<ScriptProcessorNode | null>(null);
const sourceNodeRef = useRef<MediaStreamAudioSourceNode | null>(null);
const outputGainRef = useRef<GainNode | null>(null);

// Visualizer
const inputAnalyserRef = useRef<AnalyserNode | null>(null);
const outputAnalyserRef = useRef<AnalyserNode | null>(null);
const [inputAnalyserState, setInputAnalyserState] = useState<AnalyserNode | null>(null);
const [outputAnalyserState, setOutputAnalyserState] = useState<AnalyserNode | null>(null);

// ì¬ìƒ í
const nextStartTimeRef = useRef<number>(0);
const activeSourcesRef = useRef<Set<AudioBufferSourceNode>>(new Set());

// WebSocket
const wsServiceRef = useRef<WebSocketService | null>(null);

// ìƒíƒœ ì¶”ì 
const isMutedRef = useRef(isMuted);
const firstTurnCompletedRef = useRef(false);
const secondSpeechLoggedRef = useRef(false);
```

**Ref ì‚¬ìš© ì´ìœ **:
- `useRef`ëŠ” ì»´í¬ë„ŒíŠ¸ ë¦¬ë Œë”ë§ ì‹œì—ë„ ê°’ì„ ìœ ì§€
- ì˜¤ë””ì˜¤ ë…¸ë“œì™€ WebSocketì€ React ìƒíƒœë¡œ ê´€ë¦¬ ë¶ˆí•„ìš” (UIì— ì§ì ‘ ì˜í–¥ ì—†ìŒ)
- `isMutedRef`: `onaudioprocess` ì½œë°±ì—ì„œ ìµœì‹  mute ìƒíƒœ ì°¸ì¡°

#### ì£¼ìš” í•¨ìˆ˜

##### connectToBackend()
```tsx
const connectToBackend = async () => {
  try {
    setConnectionState(ConnectionState.CONNECTING);

    // 1. AudioContext ì´ˆê¸°í™”
    const inputCtx = new AudioContext({ sampleRate: 16000 });
    const outputCtx = new AudioContext({ sampleRate: 24000 });

    // 2. ì¶œë ¥ ì²´ì¸ êµ¬ì„± (Gain â†’ Analyser â†’ Destination)
    const outGain = outputCtx.createGain();
    outGain.gain.value = volume;
    outGain.connect(outputCtx.destination);
    outputGainRef.current = outGain;

    const outAnalyser = outputCtx.createAnalyser();
    outAnalyser.fftSize = 256;
    outGain.connect(outAnalyser);
    setOutputAnalyserState(outAnalyser);

    // 3. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    // 4. ì…ë ¥ ì²´ì¸ êµ¬ì„± (Source â†’ Analyser â†’ Processor)
    const source = inputCtx.createMediaStreamSource(stream);
    const inAnalyser = inputCtx.createAnalyser();
    inAnalyser.fftSize = 256;
    source.connect(inAnalyser);
    setInputAnalyserState(inAnalyser);

    const processor = inputCtx.createScriptProcessor(4096, 1, 1);
    processor.onaudioprocess = (e) => {
      if (isMutedRef.current) return;
      const inputData = e.inputBuffer.getChannelData(0);
      const packet = createPcmBlob(inputData);
      wsServiceRef.current?.sendAudioData(packet.data, Date.now());
    };
    source.connect(processor);
    processor.connect(inputCtx.destination);

    // 5. WebSocket ì—°ê²°
    const wsUrl = import.meta.env.VITE_WS_URL || 'ws://localhost:8000/ws';
    const wsService = new WebSocketService(wsUrl, {
      onMessage: handleWebSocketMessage,
      onError: handleWebSocketError,
      onClose: handleWebSocketClose,
      onOpen: () => console.log('WebSocket connected')
    });
    wsServiceRef.current = wsService;
    wsService.connect({ language: 'auto', useWhisper: false, sampleRate: 16000 });

  } catch (e: any) {
    setError(e.message || "Failed to initialize");
    setConnectionState(ConnectionState.ERROR);
    stopAudio();
  }
};
```

##### handleWebSocketMessage()
```tsx
const handleWebSocketMessage = useCallback((message: ServerMessage) => {
  switch (message.type) {
    case 'connected':
      setConnectionState(ConnectionState.CONNECTED);
      break;

    case 'input_transcription':
      if (message.isFinal) {
        commitMessage('user', message.text || '');
        setStreamingUserText('');
      } else {
        setStreamingUserText(message.text || '');
      }
      break;

    case 'output_transcription':
      if (message.isFinal) {
        commitMessage('model', message.text || '');
        setStreamingModelText('');
      } else {
        setStreamingModelText(message.text || '');
      }
      break;

    case 'audio_response':
      // ì˜¤ë””ì˜¤ ì¬ìƒ (ìœ„ì—ì„œ ì„¤ëª…í•œ playAudioBuffer ë¡œì§)
      break;

    case 'turn_complete':
      setStreamingUserText('');
      setStreamingModelText('');
      if (!firstTurnCompletedRef.current) {
        firstTurnCompletedRef.current = true;
      }
      break;

    case 'speech_state':
      setSpeechState(message.state);
      break;

    case 'error':
      setError(message.message || 'WebSocket error');
      setConnectionState(ConnectionState.ERROR);
      break;
  }
}, [commitMessage]);
```

##### cleanupConnection()
```tsx
const cleanupConnection = useCallback((state = ConnectionState.DISCONNECTED) => {
  // 1. ì˜¤ë””ì˜¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  stopAudio();

  // 2. ìƒíƒœ ì´ˆê¸°í™”
  setConnectionState(state);
  setStreamingUserText('');
  setStreamingModelText('');
  firstTurnCompletedRef.current = false;
  secondSpeechLoggedRef.current = false;
}, [stopAudio]);
```

##### stopAudio()
```tsx
const stopAudio = useCallback(() => {
  // ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
  if (scriptProcessorRef.current) {
    scriptProcessorRef.current.disconnect();
    scriptProcessorRef.current = null;
  }
  if (sourceNodeRef.current) {
    sourceNodeRef.current.disconnect();
    sourceNodeRef.current = null;
  }
  if (inputAudioContextRef.current) {
    inputAudioContextRef.current.close();
    inputAudioContextRef.current = null;
  }

  // ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
  activeSourcesRef.current.forEach(source => source.stop());
  activeSourcesRef.current.clear();
  nextStartTimeRef.current = 0;

  if (outputAudioContextRef.current) {
    outputAudioContextRef.current.close();
    outputAudioContextRef.current = null;
  }

  // Visualizer ì´ˆê¸°í™”
  setInputAnalyserState(null);
  setOutputAnalyserState(null);
}, []);
```

### 2. WebSocketService.ts (WebSocket ê´€ë¦¬)

**ì—­í• **: WebSocket ì—°ê²° ìƒëª…ì£¼ê¸° ë° ë©”ì‹œì§€ ê´€ë¦¬

```tsx
export class WebSocketService {
  private ws: WebSocket | null = null;
  private reconnectAttempts = 0;
  private readonly maxReconnectAttempts = 5;
  private reconnectTimer: number | null = null;
  private initConfig: InitConfig | null = null;
  private shouldReconnect = true;

  constructor(
    private url: string,
    private callbacks: CallbackMap
  ) {}

  connect(config: InitConfig) {
    this.initConfig = config;
    this.shouldReconnect = true;
    this.ws = new WebSocket(this.url);

    this.ws.onopen = () => {
      this.reconnectAttempts = 0;
      this.callbacks.onOpen?.();
      this.send({ type: 'init', config });
    };

    this.ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data) as ServerMessage;
        this.callbacks.onMessage(data);
      } catch (err) {
        console.error('Malformed WebSocket message', err);
      }
    };

    this.ws.onerror = (event) => {
      this.callbacks.onError(event);
    };

    this.ws.onclose = () => {
      this.callbacks.onClose?.();
      if (this.shouldReconnect) {
        this.scheduleReconnect();
      }
    };
  }

  send(data: Record<string, unknown>) {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(data));
    }
  }

  sendAudioData(base64Data: string, timestamp: number) {
    this.send({ type: 'audio', data: base64Data, timestamp });
  }

  disconnect(options?: { notifyServer?: boolean }) {
    this.shouldReconnect = false;
    this.clearReconnectTimer();
    if (this.ws) {
      if (options?.notifyServer) {
        this.send({ type: 'close' });
      }
      this.ws.close();
      this.ws = null;
    }
  }

  private scheduleReconnect() {
    if (!this.initConfig) return;
    if (this.reconnectAttempts >= this.maxReconnectAttempts) {
      this.callbacks.onError(new Event('Maximum reconnect attempts reached'));
      return;
    }
    this.reconnectAttempts += 1;
    const delay = 2000 * this.reconnectAttempts;
    this.reconnectTimer = window.setTimeout(() => {
      this.connect(this.initConfig!);
    }, delay);
  }
}
```

### 3. Transcript.tsx (ëŒ€í™” ë‚´ìš© í‘œì‹œ)

**ì—­í• **: ë©”ì‹œì§€ ëª©ë¡ ë° ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ë Œë”ë§

```tsx
const Transcript: React.FC<TranscriptProps> = ({
  messages,
  userText,
  modelText
}) => {
  const bottomRef = useRef<HTMLDivElement>(null);

  // ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    if (bottomRef.current) {
      bottomRef.current.scrollIntoView({ behavior: 'smooth' });
    }
  }, [messages, userText, modelText]);

  // ë¹ˆ í™”ë©´ í‘œì‹œ
  if (messages.length === 0 && !userText && !modelText) {
    return (
      <div className="flex flex-col items-center justify-center h-full">
        <Bot className="w-12 h-12 mb-4" />
        <p>Ready to interpret.</p>
        <p>Speak Korean or English.</p>
      </div>
    );
  }

  return (
    <div className="flex flex-col gap-4 p-4 overflow-y-auto">
      {/* í™•ì •ëœ ë©”ì‹œì§€ ë Œë”ë§ */}
      {messages.map((msg) => (
        <div key={msg.id} className={`flex gap-3 ${
          msg.role === 'user' ? 'justify-end' : 'justify-start'
        }`}>
          {msg.role === 'model' && <Bot icon />}
          <div className={`rounded-2xl px-4 py-3 ${
            msg.role === 'user'
              ? 'bg-zinc-800 text-zinc-100'
              : 'bg-blue-950/40 border border-blue-900/50 text-blue-100'
          }`}>
            {msg.text}
          </div>
          {msg.role === 'user' && <User icon />}
        </div>
      ))}

      {/* ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©ì ì…ë ¥ */}
      {userText.trim() && (
        <div className="flex gap-3 justify-end">
          <div className="opacity-80 bg-zinc-800/80">
            {userText}
            <span className="animate-pulse">|</span>
          </div>
          <User icon />
        </div>
      )}

      {/* ìŠ¤íŠ¸ë¦¬ë° AI ì‘ë‹µ */}
      {modelText.trim() && (
        <div className="flex gap-3 justify-start">
          <Bot icon />
          <div className="opacity-80 bg-blue-950/30">
            {modelText}
            <span className="animate-pulse">|</span>
          </div>
        </div>
      )}

      <div ref={bottomRef} />
    </div>
  );
};
```

### 4. Visualizer.tsx (ì˜¤ë””ì˜¤ ì‹œê°í™”)

**ì—­í• **: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ íŒŒí˜• ë Œë”ë§

```tsx
const Visualizer: React.FC<AudioVisualizerProps> = ({
  analyser,
  isActive,
  color = '#60a5fa'
}) => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const animationRef = useRef<number | null>(null);

  useEffect(() => {
    const canvas = canvasRef.current;
    const ctx = canvas?.getContext('2d');
    if (!canvas || !ctx) return;

    const render = () => {
      const width = canvas.width;
      const height = canvas.height;

      ctx.clearRect(0, 0, width, height);

      if (!isActive || !analyser) {
        // í‰í‰í•œ ì„ 
        ctx.beginPath();
        ctx.moveTo(0, height / 2);
        ctx.lineTo(width, height / 2);
        ctx.strokeStyle = '#27272a';
        ctx.lineWidth = 2;
        ctx.stroke();
        return;
      }

      // íŒŒí˜• ë°ì´í„° ì¶”ì¶œ
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      analyser.getByteTimeDomainData(dataArray);

      // íŒŒí˜• ê·¸ë¦¬ê¸°
      ctx.lineWidth = 3;
      ctx.strokeStyle = color;
      ctx.beginPath();

      const sliceWidth = width / bufferLength;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const v = dataArray[i] / 128.0;
        const y = v * height / 2;

        if (i === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }

        x += sliceWidth;
      }

      ctx.lineTo(canvas.width, canvas.height / 2);
      ctx.stroke();

      animationRef.current = requestAnimationFrame(render);
    };

    render();

    return () => {
      if (animationRef.current !== null) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, [analyser, isActive, color]);

  return (
    <canvas
      ref={canvasRef}
      width={400}
      height={80}
      className="w-full h-20 rounded-lg bg-zinc-900/50"
    />
  );
};
```

### 5. SpeechStateIndicator.tsx (ìŒì„± ìƒíƒœ í‘œì‹œ)

**ì—­í• **: í˜„ì¬ ìŒì„± ìƒíƒœë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ

```tsx
const SpeechStateIndicator: React.FC<{ state: SpeechState }> = ({ state }) => {
  const stateConfig = {
    speaking: {
      bgColor: 'bg-green-500/20',
      borderColor: 'border-green-500/50',
      textColor: 'text-green-400',
      icon: 'ğŸ¤',
      text: 'ë§ì”€í•˜ì„¸ìš”...',
      animation: 'animate-pulse-custom'
    },
    silent: {
      bgColor: 'bg-zinc-800/50',
      borderColor: 'border-zinc-700',
      textColor: 'text-zinc-400',
      icon: 'ğŸ‘‚',
      text: 'ë“£ê³  ìˆìŠµë‹ˆë‹¤...',
      animation: ''
    },
    processing: {
      bgColor: 'bg-blue-500/20',
      borderColor: 'border-blue-500/50',
      textColor: 'text-blue-400',
      icon: 'â³',
      text: 'ì²˜ë¦¬ ì¤‘...',
      animation: 'animate-spin-slow'
    }
  };

  const config = stateConfig[state];

  return (
    <div className={`flex items-center gap-3 px-4 py-3 rounded-xl border
                     ${config.bgColor} ${config.borderColor}`}>
      <div className={`text-2xl ${config.animation}`}>
        {config.icon}
      </div>
      <div className="flex flex-col">
        <span className={`text-sm font-medium ${config.textColor}`}>
          {config.text}
        </span>
        <span className="text-xs text-zinc-500">
          {state}
        </span>
      </div>
    </div>
  );
};
```

---

## ë°ì´í„° íë¦„ë„

### ì „ì²´ ë°ì´í„° íë¦„ (End-to-End)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User speaks Korean                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Audio Capture                                                 â”‚
â”‚    â€¢ Microphone â†’ MediaStream                                    â”‚
â”‚    â€¢ Sample Rate: 16kHz                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Audio Processing                                              â”‚
â”‚    â€¢ ScriptProcessorNode: 4096 samples buffer                    â”‚
â”‚    â€¢ Float32Array â†’ Int16 PCM conversion                         â”‚
â”‚    â€¢ PCM â†’ Base64 encoding                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. WebSocket Transmission (Every 256ms)                          â”‚
â”‚    â€¢ Message: { type: 'audio', data: base64, timestamp }        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Backend Processing                                            â”‚
â”‚    â€¢ Base64 â†’ PCM decoding                                       â”‚
â”‚    â€¢ Stream to Gemini Live API (gRPC)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Gemini Live API Processing                                    â”‚
â”‚    â€¢ Speech-to-Text (Korean)                                     â”‚
â”‚    â€¢ Translation (Korean â†’ English)                              â”‚
â”‚    â€¢ Text-to-Speech (English)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Backend Response Streaming                                    â”‚
â”‚    â€¢ input_transcription: "ì•ˆë…•í•˜ì„¸ìš”" (isFinal: false/true)      â”‚
â”‚    â€¢ output_transcription: "Hello" (isFinal: false/true)         â”‚
â”‚    â€¢ audio_response: Base64 PCM chunks (24kHz)                   â”‚
â”‚    â€¢ speech_state: speaking/silent/processing                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Frontend Message Handling                                     â”‚
â”‚    â€¢ input_transcription â†’ streamingUserText or commitMessage    â”‚
â”‚    â€¢ output_transcription â†’ streamingModelText or commitMessage  â”‚
â”‚    â€¢ audio_response â†’ decodeAudioData â†’ playback queue           â”‚
â”‚    â€¢ speech_state â†’ SpeechStateIndicator update                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Audio Playback                                                â”‚
â”‚    â€¢ Base64 â†’ ArrayBuffer â†’ AudioBuffer (24kHz Float32)          â”‚
â”‚    â€¢ BufferSourceNode â†’ GainNode â†’ Destination                   â”‚
â”‚    â€¢ Scheduled playback (nextStartTime queue)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. UI Updates                                                    â”‚
â”‚    â€¢ Transcript: Display messages and streaming text             â”‚
â”‚    â€¢ Visualizer: Render input/output waveforms                   â”‚
â”‚    â€¢ SpeechStateIndicator: Update state badge                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User hears English audio                       â”‚
â”‚                   User sees "Hello" transcription                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìƒíƒœ ì „ì´ë„ (State Transitions)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DISCONNECTED   â”‚ (Initial State)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ User clicks "Start Session"
         â”‚ connectToBackend()
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CONNECTING    â”‚ (Initializing Audio + WebSocket)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ onopen event + { type: 'connected' }
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CONNECTED     â”‚ â—„â”€â”€â”€â”€â” (Active Session)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
         â”‚                â”‚ Reconnect successful
         â”‚                â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Error / User clicks "Stop" / Max reconnects
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ERROR       â”‚ or DISCONNECTED
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë©”ì‹œì§€ ì²˜ë¦¬ íë¦„ (Message Processing)

```
WebSocket Message Received
         â”‚
         â–¼
   Parse JSON
         â”‚
         â–¼
   Switch (message.type)
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º 'connected' â”€â”€â”€â”€â”€â”€â–º setConnectionState(CONNECTED)
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º 'input_transcription'
         â”‚                 â”‚
         â”‚                 â”œâ”€â–º isFinal? â”€â”€Noâ”€â”€â–º setStreamingUserText(text)
         â”‚                 â”‚
         â”‚                 â””â”€â–º Yes â”€â”€â–º commitMessage('user', text)
         â”‚                           â””â”€â–º setStreamingUserText('')
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º 'output_transcription'
         â”‚                 â”‚
         â”‚                 â”œâ”€â–º isFinal? â”€â”€Noâ”€â”€â–º setStreamingModelText(text)
         â”‚                 â”‚
         â”‚                 â””â”€â–º Yes â”€â”€â–º commitMessage('model', text)
         â”‚                           â””â”€â–º setStreamingModelText('')
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º 'audio_response'
         â”‚                 â”‚
         â”‚                 â””â”€â–º base64ToArrayBuffer()
         â”‚                           â”‚
         â”‚                           â””â”€â–º decodeAudioData()
         â”‚                                     â”‚
         â”‚                                     â””â”€â–º playAudioBuffer()
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º 'turn_complete' â”€â”€â”€â”€â”€â”€â–º Clear streaming text
         â”‚                                Set firstTurnCompleted flag
         â”‚
         â”œâ”€â”€â”€â”€â”€â–º 'speech_state' â”€â”€â”€â”€â”€â”€â”€â”€â–º setSpeechState(state)
         â”‚
         â””â”€â”€â”€â”€â”€â–º 'error' â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º setError(message)
                                          setConnectionState(ERROR)
```

---

## ê¸°ìˆ  ìŠ¤íƒ

### Frontend

#### í•µì‹¬ í”„ë ˆì„ì›Œí¬
- **React 19.2.1**: UI ì»´í¬ë„ŒíŠ¸ ë° ìƒíƒœ ê´€ë¦¬
- **TypeScript 5.8.2**: ì •ì  íƒ€ì… ì‹œìŠ¤í…œ

#### ë¹Œë“œ ë„êµ¬
- **Vite 6.2.0**: ë¹ ë¥¸ ê°œë°œ ì„œë²„ ë° ë²ˆë“¤ëŸ¬
- **@vitejs/plugin-react**: React Fast Refresh ì§€ì›

#### UI ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Tailwind CSS**: ìœ í‹¸ë¦¬í‹° ê¸°ë°˜ ìŠ¤íƒ€ì¼ë§ (ì„¤ì • íŒŒì¼ ì—†ìŒ, JIT ëª¨ë“œ)
- **lucide-react 0.559.0**: ì•„ì´ì½˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Settings2, Mic, MicOff, Power, Bot, User, AlertCircle, Volume2)

#### Web APIs
- **Web Audio API**: ì˜¤ë””ì˜¤ ì…ì¶œë ¥ ë° ì‹œê°í™”
  - `AudioContext`: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì»¨í…ìŠ¤íŠ¸
  - `MediaStreamAudioSourceNode`: ë§ˆì´í¬ ì…ë ¥
  - `ScriptProcessorNode`: ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
  - `AnalyserNode`: íŒŒí˜• ë°ì´í„° ì¶”ì¶œ
  - `GainNode`: ë³¼ë¥¨ ì œì–´
  - `AudioBufferSourceNode`: ì˜¤ë””ì˜¤ ì¬ìƒ
- **WebSocket API**: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- **Canvas API**: ì˜¤ë””ì˜¤ íŒŒí˜• ì‹œê°í™”
- **MediaDevices API**: ë§ˆì´í¬ ì ‘ê·¼ (`getUserMedia`)

### Backend (ì¶”ì •)

**ì°¸ê³ **: ë°±ì—”ë“œ ì½”ë“œëŠ” ì œê³µë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ í”„ë¡œí† ì½œ ê¸°ë°˜ ì¶”ì •

#### ì„œë²„ í”„ë ˆì„ì›Œí¬
- **FastAPI** (Python): WebSocket ì§€ì›, ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì„œë²„
- **uvicorn**: ASGI ì„œë²„

#### AI/ML í†µí•©
- **Google Gemini Live API**:
  - ì‹¤ì‹œê°„ STT (Speech-to-Text)
  - ì–¸ì–´ ë²ˆì—­ (KO â†” EN)
  - ì‹¤ì‹œê°„ TTS (Text-to-Speech)
- **gRPC Streaming**: Gemini APIì™€ì˜ ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë° í†µì‹ 

#### ë°ì´í„° ì²˜ë¦¬
- **Base64**: ì˜¤ë””ì˜¤ ë°ì´í„° ì¸ì½”ë”©/ë””ì½”ë”©
- **PCM Audio Processing**: 16-bit PCM ì²˜ë¦¬

### ê°œë°œ ë„êµ¬
- **Node.js**: JavaScript ëŸ°íƒ€ì„
- **npm**: íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €

### í™˜ê²½ ë³€ìˆ˜
```env
VITE_WS_URL=ws://localhost:8000/ws   # WebSocket ì„œë²„ URL
VITE_UI_PORT=3000                     # ê°œë°œ ì„œë²„ í¬íŠ¸
```

---

## ì£¼ìš” ê¸°ìˆ ì  ê²°ì • ë° ìµœì í™”

### 1. WebSocket vs HTTP Polling
**ì„ íƒ**: WebSocket
**ì´ìœ **:
- ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹  í•„ìš”
- ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°ì€ ì§€ì†ì ì¸ ë°ì´í„° ì „ì†¡ ìš”êµ¬
- HTTP í´ë§ ëŒ€ë¹„ ë‚®ì€ ì§€ì—°ì‹œê°„ (< 50ms)
- ì„œë²„ ë¶€í•˜ ê°ì†Œ

### 2. ScriptProcessorNode vs AudioWorklet
**ì„ íƒ**: ScriptProcessorNode
**ì´ìœ **:
- ê´‘ë²”ìœ„í•œ ë¸Œë¼ìš°ì € ì§€ì› (Safari, older Chrome)
- AudioWorkletì€ ìµœì‹  ë¸Œë¼ìš°ì €ë§Œ ì§€ì›
- Deprecatedì´ì§€ë§Œ ì—¬ì „íˆ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™

**í–¥í›„ ê°œì„ **: AudioWorkletìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³ ë ¤

### 3. 16kHz ìƒ˜í”Œë ˆì´íŠ¸ (ì…ë ¥)
**ì´ìœ **:
- Gemini Live API ìš”êµ¬ì‚¬í•­
- ìŒì„± ì¸ì‹ì— ì¶©ë¶„í•œ í’ˆì§ˆ (ì¸ê°„ ìŒì„± ì£¼íŒŒìˆ˜: 300~3400 Hz)
- ë‚®ì€ ëŒ€ì—­í­ ì‚¬ìš© (24kHz ëŒ€ë¹„ 33% ì ˆê°)

### 4. 24kHz ìƒ˜í”Œë ˆì´íŠ¸ (ì¶œë ¥)
**ì´ìœ **:
- Gemini API TTS ì¶œë ¥ ê¸°ë³¸ê°’
- 16kHzë³´ë‹¤ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± í’ˆì§ˆ
- 48kHz ëŒ€ë¹„ ëŒ€ì—­í­ ì ˆì•½

### 5. Base64 ì¸ì½”ë”©
**ì´ìœ **:
- WebSocketì€ í…ìŠ¤íŠ¸ ë˜ëŠ” ë°”ì´ë„ˆë¦¬ í”„ë ˆì„ ì§€ì›
- JSON ë©”ì‹œì§€ ë‚´ ì˜¤ë””ì˜¤ í¬í•¨ì„ ìœ„í•´ Base64 í•„ìš”
- ëŒ€ì•ˆ: Binary WebSocket (êµ¬í˜„ ë³µì¡ë„ ì¦ê°€)

### 6. ì˜¤ë””ì˜¤ ì¬ìƒ íì‰ ì‹œìŠ¤í…œ
**ì´ìœ **:
- WebSocketìœ¼ë¡œ ì˜¤ë””ì˜¤ê°€ ì²­í¬ ë‹¨ìœ„ë¡œ ë„ì°©
- ì¦‰ì‹œ ì¬ìƒ ì‹œ ëŠê¹€ í˜„ìƒ ë°œìƒ
- `nextStartTime` ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ë§¤ë„ëŸ¬ìš´ ì—°ì† ì¬ìƒ

### 7. React Refs for Audio Nodes
**ì´ìœ **:
- Web Audio API ê°ì²´ëŠ” React ìƒíƒœë¡œ ê´€ë¦¬ ë¶ˆí•„ìš”
- ë¦¬ë Œë”ë§ ì‹œ ì˜¤ë””ì˜¤ ë…¸ë“œ ì¬ìƒì„± ë°©ì§€
- ì„±ëŠ¥ ìµœì í™” ë° ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€

### 8. ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ë¶„ë¦¬ (`streamingUserText` vs `streamingModelText`)
**ì´ìœ **:
- ì‚¬ìš©ìì™€ AI ì‘ë‹µì´ ë™ì‹œì— ìŠ¤íŠ¸ë¦¬ë°ë  ìˆ˜ ìˆìŒ
- ë‹¨ì¼ ìƒíƒœ ì‚¬ìš© ì‹œ í…ìŠ¤íŠ¸ ì¶©ëŒ ê°€ëŠ¥
- ë…ë¦½ì ì¸ ìƒíƒœë¡œ ëª…í™•í•œ ë¶„ë¦¬

### 9. Tailwind CSS
**ì´ìœ **:
- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
- ì¼ê´€ëœ ë””ìì¸ ì‹œìŠ¤í…œ
- ë²ˆë“¤ í¬ê¸° ìµœì í™” (JIT ëª¨ë“œ)
- ì»¤ìŠ¤í…€ CSS ì‘ì„± ìµœì†Œí™”

### 10. TypeScript
**ì´ìœ **:
- íƒ€ì… ì•ˆì „ì„±ìœ¼ë¡œ ëŸ°íƒ€ì„ ì—ëŸ¬ ê°ì†Œ
- IDE ìë™ì™„ì„± ë° ë¦¬íŒ©í† ë§ ì§€ì›
- WebSocket ë©”ì‹œì§€ íƒ€ì… ì •ì˜ë¡œ í”„ë¡œí† ì½œ ëª…í™•í™”

---

## ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸

### 1. ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸° (4096 samples)
- **ì§€ì—°**: 256ms (4096 / 16000)
- **ê· í˜•**: ë‚®ì€ ì§€ì—° vs CPU ì‚¬ìš©ë¥ 
- **ëŒ€ì•ˆ**: 2048 (128ms, CPU ë¶€í•˜ ì¦ê°€) or 8192 (512ms, ì§€ì—° ì¦ê°€)

### 2. AnalyserNode FFT í¬ê¸° (256)
- **íŠ¸ë ˆì´ë“œì˜¤í”„**: ì£¼íŒŒìˆ˜ í•´ìƒë„ vs ì„±ëŠ¥
- 256ì€ ì‹œê°í™”ì— ì¶©ë¶„í•˜ê³  ì„±ëŠ¥ ì˜í–¥ ìµœì†Œ

### 3. Canvas ì• ë‹ˆë©”ì´ì…˜ (requestAnimationFrame)
- ë¸Œë¼ìš°ì € ìµœì í™” (60fps ìë™ ì¡°ì ˆ)
- íƒ­ì´ ë°±ê·¸ë¼ìš´ë“œì¼ ë•Œ ì¼ì‹œ ì¤‘ì§€

### 4. WebSocket ì¬ì—°ê²° Exponential Backoff
- ì„œë²„ ë¶€í•˜ ë°©ì§€
- ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì • ì‹œ ì ì§„ì  ì¬ì‹œë„

### 5. React.memo ì ìš© ê°€ëŠ¥ ì»´í¬ë„ŒíŠ¸
- `Visualizer`: props ë³€ê²½ ì‹œì—ë§Œ ë¦¬ë Œë”ë§
- `Transcript`: messages ë³€ê²½ ì‹œì—ë§Œ ë¦¬ë Œë”ë§
- `SpeechStateIndicator`: state ë³€ê²½ ì‹œì—ë§Œ ë¦¬ë Œë”ë§

**í˜„ì¬ ë¯¸ì ìš©**: í”„ë¡œí† íƒ€ì… ë‹¨ê³„, í–¥í›„ ìµœì í™” ì—¬ì§€

### 6. ë©”ì‹œì§€ ê°€ìƒí™” (Virtual Scrolling)
**í˜„ì¬**: ëª¨ë“  ë©”ì‹œì§€ ë Œë”ë§
**ê°œì„  ê°€ëŠ¥**: ê¸´ ëŒ€í™” ì‹œ react-window ë“± ì‚¬ìš©í•˜ì—¬ ë·°í¬íŠ¸ ë‚´ ë©”ì‹œì§€ë§Œ ë Œë”ë§

---

## ì•Œë ¤ì§„ ì œí•œì‚¬í•­ ë° ê°œì„  ë°©í–¥

### ì œí•œì‚¬í•­

1. **ScriptProcessorNode Deprecation**
   - í–¥í›„ ë¸Œë¼ìš°ì €ì—ì„œ ì œê±° ê°€ëŠ¥
   - í•´ê²°: AudioWorkletìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”

2. **ë¸Œë¼ìš°ì € í˜¸í™˜ì„±**
   - Safari: WebSocket, Web Audio API ì¼ë¶€ ì œí•œ
   - ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €: ë°±ê·¸ë¼ìš´ë“œ ì˜¤ë””ì˜¤ ì¬ìƒ ì œí•œ

3. **ì—ëŸ¬ ë³µêµ¬**
   - ì¼ë¶€ ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‚¬ìš©ì ìˆ˜ë™ ê°œì… í•„ìš”
   - í•´ê²°: ë” ì„¸ë°€í•œ ì—ëŸ¬ í•¸ë“¤ë§ ë° ìë™ ë³µêµ¬

4. **ì˜¤í”„ë¼ì¸ ì§€ì› ì—†ìŒ**
   - ì¸í„°ë„· ì—°ê²° í•„ìˆ˜
   - í•´ê²°: Service Worker ë° ì˜¤í”„ë¼ì¸ ê°ì§€

5. **ëŒ€ìš©ëŸ‰ ëŒ€í™” ê¸°ë¡**
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
   - í•´ê²°: ë©”ì‹œì§€ í˜ì´ì§€ë„¤ì´ì…˜ ë˜ëŠ” ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ì €ì¥

### ê°œì„  ë°©í–¥

#### ë‹¨ê¸° (1-2ì£¼)
- [ ] AudioWorklet ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] ì—ëŸ¬ ë©”ì‹œì§€ ë‹¤êµ­ì–´í™” (í•œ/ì˜)
- [ ] ë¡œë”© ìŠ¤í”¼ë„ˆ ë° ìƒíƒœ í‘œì‹œ ê°œì„ 
- [ ] í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ (Space: Mute Toggle, Esc: Disconnect)

#### ì¤‘ê¸° (1-2ê°œì›”)
- [ ] ëŒ€í™” ê¸°ë¡ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°
- [ ] ì‚¬ìš©ì ì„¤ì • (ë³¼ë¥¨, ìƒ˜í”Œë ˆì´íŠ¸, ì–¸ì–´)
- [ ] PWA ì§€ì› (ì˜¤í”„ë¼ì¸ ê°ì§€, ì„¤ì¹˜ ê°€ëŠ¥)
- [ ] ìŒì„± í™œì„±í™” ê°ì§€ (VAD) - ë¬´ìŒ êµ¬ê°„ í•„í„°ë§

#### ì¥ê¸° (3ê°œì›”+)
- [ ] ë‹¤ì¤‘ ì–¸ì–´ ìŒ ì§€ì› (í•œ-ì˜ ì™¸)
- [ ] ëŒ€í™” ë‚´ë³´ë‚´ê¸° (TXT, PDF)
- [ ] ì‹¤ì‹œê°„ ìë§‰ ì˜¤ë²„ë ˆì´
- [ ] AI ì‘ë‹µ ì¤‘ë‹¨ ê¸°ëŠ¥ (interrupt ë©”ì‹œì§€ í™œìš©)
- [ ] ìŒì„± ê°ì • ë¶„ì„ ë° í‘œì‹œ

---

## ê²°ë¡ 

Gemini Live InterpreterëŠ” **ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŒì„± í†µì—­**ì„ ìœ„í•œ í˜„ëŒ€ì ì¸ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. WebSocket ê¸°ë°˜ì˜ ì €ì§€ì—° í†µì‹ , Web Audio APIë¥¼ í™œìš©í•œ ì •êµí•œ ì˜¤ë””ì˜¤ ì²˜ë¦¬, ê·¸ë¦¬ê³  ì§ê´€ì ì¸ React UIë¥¼ í†µí•´ ì‚¬ìš©ìì—ê²Œ ë§¤ë„ëŸ¬ìš´ í†µì—­ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

í•µì‹¬ ê°•ì :
- âœ… **ì‹¤ì‹œê°„ì„±**: 256ms ì£¼ê¸°ì˜ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„
- âœ… **ì‹œê°ì  í”¼ë“œë°±**: íŒŒí˜• ì‹œê°í™” ë° ìƒíƒœ í‘œì‹œë¡œ ì‹œìŠ¤í…œ íˆ¬ëª…ì„± í™•ë³´
- âœ… **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ì»´í¬ë„ŒíŠ¸ ê¸°ë°˜ ì„¤ê³„ë¡œ ìœ ì§€ë³´ìˆ˜ ë° ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´
- âœ… **ì‚¬ìš©ì ì¤‘ì‹¬ UI**: ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤ë¡œ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥

ì´ ë¬¸ì„œëŠ” ì‹œìŠ¤í…œì˜ ëª¨ë“  ì¸¡ë©´ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ê°œë°œìê°€ ì½”ë“œë² ì´ìŠ¤ë¥¼ ì´í•´í•˜ê³  í–¥í›„ ê°œì„  ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ê¸°ìˆ ì  ê¸°ë°˜ì„ ì œê³µí•©ë‹ˆë‹¤.
