# Gemini Live Interpreter v2 - ë°±ì—”ë“œ ë¶„ë¦¬ ì•„í‚¤í…ì²˜ ì„¤ê³„

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì•„í‚¤í…ì²˜ ë¹„êµ](#ì•„í‚¤í…ì²˜-ë¹„êµ)
3. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
4. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
5. [í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½ì‚¬í•­](#í”„ë¡ íŠ¸ì—”ë“œ-ë³€ê²½ì‚¬í•­)
6. [ë°±ì—”ë“œ êµ¬ì¡°](#ë°±ì—”ë“œ-êµ¬ì¡°)
7. [Rust + Whisper í†µí•©](#rust--whisper-í†µí•©)
8. [ë°°í¬ ì „ëµ](#ë°°í¬-ì „ëµ)
9. [êµ¬í˜„ ë‹¨ê³„](#êµ¬í˜„-ë‹¨ê³„)
10. [í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ](#í”„ë¡¬í”„íŠ¸-ê°€ì´ë“œ)

---

## ê°œìš”

### ëª©í‘œ
ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ Gemini Live Interpreterë¥¼ ë°±ì—”ë“œ ë¶„ë¦¬ ì•„í‚¤í…ì²˜ë¡œ ì¬êµ¬ì„±í•˜ì—¬:
- **ë³´ì•ˆ ê°•í™”**: API í‚¤ë¥¼ ë°±ì—”ë“œì—ì„œ ê´€ë¦¬
- **ì„±ëŠ¥ ê°œì„ **: Rust ê¸°ë°˜ Whisper STTë¡œ ê³ ì„±ëŠ¥ ìŒì„± ì¸ì‹ ì œê³µ
- **í™•ì¥ì„±**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¡œ ê° ì»´í¬ë„ŒíŠ¸ ë…ë¦½ ë°°í¬

### í•µì‹¬ ë³€ê²½ì‚¬í•­
- âœ… UIëŠ” ê¸°ì¡´ React ì½”ë“œ ìœ ì§€
- âœ… Gemini API í˜¸ì¶œì„ ë°±ì—”ë“œë¡œ ì´ë™
- âœ… WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- âœ… Rust + Whisperë¡œ STT ì„±ëŠ¥ í–¥ìƒ
- âœ… Netlify (í”„ë¡ íŠ¸ì—”ë“œ) + Render.com (ë°±ì—”ë“œ) ë°°í¬

---

## ì•„í‚¤í…ì²˜ ë¹„êµ

### í˜„ì¬ ì•„í‚¤í…ì²˜ (v1)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ë¸Œë¼ìš°ì € (React)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ ë§ˆì´í¬ ì…ë ¥ (Web Audio API)      â”‚ â”‚
â”‚  â”‚ â€¢ Gemini API ì§ì ‘ í˜¸ì¶œ             â”‚ â”‚
â”‚  â”‚ â€¢ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° ì¬ìƒ              â”‚ â”‚
â”‚  â”‚ â€¢ ì „ì‚¬ í…ìŠ¤íŠ¸ í‘œì‹œ                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Gemini API   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ë¬¸ì œì :**
- API í‚¤ê°€ í´ë¼ì´ì–¸íŠ¸ì— ë…¸ì¶œ
- ë¸Œë¼ìš°ì € ì„±ëŠ¥ì— ì˜ì¡´ì ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬
- ì„œë²„ ì‚¬ì´ë“œ ë¡œì§ ì¶”ê°€ ì–´ë ¤ì›€
- í™•ì¥ì„± ì œí•œ

### ìƒˆ ì•„í‚¤í…ì²˜ (v2)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ë¸Œë¼ìš°ì € (React - Netlify)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ ë§ˆì´í¬ ì…ë ¥ (Web Audio API)      â”‚ â”‚
â”‚  â”‚ â€¢ WebSocket í´ë¼ì´ì–¸íŠ¸             â”‚ â”‚
â”‚  â”‚ â€¢ ì˜¤ë””ì˜¤ ì¬ìƒ                      â”‚ â”‚
â”‚  â”‚ â€¢ UI/UX                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†• WebSocket (ì‹¤ì‹œê°„ ì–‘ë°©í–¥)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë°±ì—”ë“œ ì„œë²„ (Python - Render.com)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ FastAPI + WebSocket                â”‚ â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚ â”‚ Gemini API â”‚  â”‚ Rust Whisper  â”‚ â”‚ â”‚
â”‚  â”‚ â”‚ Integrationâ”‚  â”‚ STT Service   â”‚ â”‚ â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚ â€¢ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬               â”‚ â”‚
â”‚  â”‚ â€¢ ë²ˆì—­ ë¡œì§                        â”‚ â”‚
â”‚  â”‚ â€¢ API í‚¤ ê´€ë¦¬                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì¥ì :**
- âœ… API í‚¤ ë³´ì•ˆ
- âœ… ê³ ì„±ëŠ¥ STT (Rust + Whisper)
- âœ… ì„œë²„ ì‚¬ì´ë“œ ë¡œì§ í™•ì¥ ìš©ì´
- âœ… ê° ì»´í¬ë„ŒíŠ¸ ë…ë¦½ ë°°í¬ ë° ìŠ¤ì¼€ì¼ë§

---

## ê¸°ìˆ  ìŠ¤íƒ

### í”„ë¡ íŠ¸ì—”ë“œ (Netlify)
| ê¸°ìˆ  | ë²„ì „ | ì—­í•  |
|------|------|------|
| React | 19.2.1 | UI í”„ë ˆì„ì›Œí¬ |
| TypeScript | 5.8.2 | íƒ€ì… ì•ˆì •ì„± |
| Vite | 6.2.0 | ë¹Œë“œ ë„êµ¬ |
| Tailwind CSS | CDN | ìŠ¤íƒ€ì¼ë§ |
| Lucide React | 0.559.0 | ì•„ì´ì½˜ |
| **WebSocket** | **Native API** | **ì‹¤ì‹œê°„ í†µì‹ ** |

**ì¶”ê°€ í•„ìš” ì˜ì¡´ì„±:**
```json
{
  "dependencies": {
    // ê¸°ì¡´ ìœ ì§€
    "react": "^19.2.1",
    "react-dom": "^19.2.1",
    "lucide-react": "^0.559.0",
    
    // ì œê±°: @google/genai (ë°±ì—”ë“œë¡œ ì´ë™)
  }
}
```

### ë°±ì—”ë“œ (Render.com)
| ê¸°ìˆ  | ë²„ì „/íƒ€ì… | ì—­í•  |
|------|-----------|------|
| Python | 3.11+ | ì£¼ ì–¸ì–´ |
| FastAPI | Latest | ì›¹ í”„ë ˆì„ì›Œí¬ + WebSocket |
| uvicorn | Latest | ASGI ì„œë²„ |
| websockets | Latest | WebSocket ì§€ì› |
| google-generativeai | Latest | Gemini API í´ë¼ì´ì–¸íŠ¸ |
| pydantic | Latest | ë°ì´í„° ê²€ì¦ |
| python-dotenv | Latest | í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ |
| **PyO3** | **Latest** | **Rust ë°”ì¸ë”©** |

**requirements.txt:**
```txt
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
websockets>=12.0
google-generativeai>=0.3.0
pydantic>=2.5.0
python-dotenv>=1.0.0
pyo3>=0.20.0
numpy>=1.24.0
```

### Rust STT ëª¨ë“ˆ
| ê¸°ìˆ  | ì—­í•  |
|------|------|
| Rust | 1.75+ |
| whisper.cpp | OpenAI Whisper C++ êµ¬í˜„ |
| whisper-rs | Rust ë°”ì¸ë”© |
| PyO3 | Python-Rust FFI |

**Cargo.toml:**
```toml
[package]
name = "whisper-stt"
version = "0.1.0"
edition = "2021"

[dependencies]
pyo3 = { version = "0.20", features = ["extension-module"] }
whisper-rs = "0.10"
tokio = { version = "1", features = ["full"] }

[lib]
name = "whisper_stt"
crate-type = ["cdylib"]
```

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ ë°ì´í„° íë¦„

```
1. ì‚¬ìš©ì ìŒì„± ì…ë ¥
   â†“
2. ë¸Œë¼ìš°ì €: Web Audio APIë¡œ PCM ì¶”ì¶œ
   â†“
3. ë¸Œë¼ìš°ì € â†’ ë°±ì—”ë“œ: WebSocketìœ¼ë¡œ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
   â†“
4. ë°±ì—”ë“œ: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì„ íƒ
   â”œâ”€ Option A: Gemini Native Audio API
   â”‚  â””â”€ Gemini APIë¡œ ì˜¤ë””ì˜¤ ì§ì ‘ ì „ì†¡
   â”‚     â””â”€ ë²ˆì—­ + TTS ì‘ë‹µ ìˆ˜ì‹ 
   â””â”€ Option B: Whisper STT + Gemini Text
      â”œâ”€ Rust Whisperë¡œ STT ì²˜ë¦¬
      â”œâ”€ í…ìŠ¤íŠ¸ë¥¼ Gemini Text APIë¡œ ë²ˆì—­
      â””â”€ (ì„ íƒ) Gemini TTSë¡œ ìŒì„± í•©ì„±
   â†“
5. ë°±ì—”ë“œ â†’ ë¸Œë¼ìš°ì €: WebSocketìœ¼ë¡œ ê²°ê³¼ ì „ì†¡
   â”œâ”€ ì „ì‚¬ í…ìŠ¤íŠ¸ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)
   â”œâ”€ ë²ˆì—­ í…ìŠ¤íŠ¸
   â””â”€ ì˜¤ë””ì˜¤ ë°ì´í„° (base64 PCM)
   â†“
6. ë¸Œë¼ìš°ì €: ì˜¤ë””ì˜¤ ì¬ìƒ + UI ì—…ë°ì´íŠ¸
```

### WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ

#### í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„

**1. ì—°ê²° ì´ˆê¸°í™”**
```json
{
  "type": "init",
  "config": {
    "language": "auto",  // "ko", "en", "auto"
    "useWhisper": false,  // true: Whisper STT ì‚¬ìš©
    "sampleRate": 16000
  }
}
```

**2. ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼**
```json
{
  "type": "audio",
  "data": "base64_encoded_pcm_data",
  "timestamp": 1234567890
}
```

**3. ì¸í„°ëŸ½íŠ¸ (ì‚¬ìš©ì ë§í•  ë•Œ AI ì¤‘ë‹¨)**
```json
{
  "type": "interrupt"
}
```

**4. ì—°ê²° ì¢…ë£Œ**
```json
{
  "type": "close"
}
```

#### ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸

**1. ì—°ê²° í™•ì¸**
```json
{
  "type": "connected",
  "sessionId": "uuid-session-id"
}
```

**2. ì…ë ¥ ì „ì‚¬ (ì‹¤ì‹œê°„)**
```json
{
  "type": "input_transcription",
  "text": "ì•ˆë…•í•˜ì„¸ìš”",
  "isFinal": false,
  "language": "ko"
}
```

**3. ì¶œë ¥ ì „ì‚¬ (ì‹¤ì‹œê°„)**
```json
{
  "type": "output_transcription",
  "text": "Hello",
  "isFinal": false,
  "language": "en"
}
```

**4. ì˜¤ë””ì˜¤ ì‘ë‹µ**
```json
{
  "type": "audio_response",
  "data": "base64_encoded_pcm_data",
  "sampleRate": 24000
}
```

**5. í„´ ì™„ë£Œ**
```json
{
  "type": "turn_complete",
  "inputText": "ì•ˆë…•í•˜ì„¸ìš”",
  "outputText": "Hello"
}
```

**6. ì—ëŸ¬**
```json
{
  "type": "error",
  "message": "API rate limit exceeded",
  "code": "RATE_LIMIT"
}
```

---

## í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½ì‚¬í•­

### 1. WebSocket í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

**ìƒˆ íŒŒì¼: `src/services/WebSocketService.ts`**
```typescript
export class WebSocketService {
  private ws: WebSocket | null = null;
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 5;
  
  constructor(
    private url: string,
    private onMessage: (data: any) => void,
    private onError: (error: any) => void
  ) {}

  connect(config: { language: string; useWhisper: boolean; sampleRate: number }) {
    this.ws = new WebSocket(this.url);
    
    this.ws.onopen = () => {
      console.log('WebSocket Connected');
      this.reconnectAttempts = 0;
      this.send({ type: 'init', config });
    };

    this.ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      this.onMessage(data);
    };

    this.ws.onerror = (error) => {
      console.error('WebSocket Error:', error);
      this.onError(error);
    };

    this.ws.onclose = () => {
      console.log('WebSocket Disconnected');
      this.attemptReconnect();
    };
  }

  send(data: any) {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(data));
    }
  }

  sendAudioData(pcmData: string, timestamp: number) {
    this.send({ type: 'audio', data: pcmData, timestamp });
  }

  interrupt() {
    this.send({ type: 'interrupt' });
  }

  disconnect() {
    if (this.ws) {
      this.send({ type: 'close' });
      this.ws.close();
      this.ws = null;
    }
  }

  private attemptReconnect() {
    if (this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      setTimeout(() => {
        console.log(`Reconnecting... (${this.reconnectAttempts}/${this.maxReconnectAttempts})`);
        this.connect({ language: 'auto', useWhisper: false, sampleRate: 16000 });
      }, 2000 * this.reconnectAttempts);
    }
  }
}
```

### 2. App.tsx ìˆ˜ì •

**ì£¼ìš” ë³€ê²½ì‚¬í•­:**
```typescript
import { WebSocketService } from './services/WebSocketService';

function App() {
  const [wsService, setWsService] = useState<WebSocketService | null>(null);
  
  // Gemini ì—°ê²° ëŒ€ì‹  WebSocket ì—°ê²°
  const connectToBackend = async () => {
    try {
      setConnectionState(ConnectionState.CONNECTING);
      setError(null);

      // 1. ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
      const InputContextClass = (window.AudioContext || (window as any).webkitAudioContext);
      const inputCtx = new InputContextClass({ sampleRate: 16000 });
      const outputCtx = new InputContextClass({ sampleRate: 24000 });
      
      // ... (ê¸°ì¡´ ì˜¤ë””ì˜¤ ì„¤ì • ì½”ë“œ)

      // 2. WebSocket ì—°ê²°
      const wsUrl = import.meta.env.VITE_WS_URL || 'ws://localhost:8000/ws';
      const ws = new WebSocketService(
        wsUrl,
        handleWebSocketMessage,  // ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
        handleWebSocketError     // ì—ëŸ¬ í•¸ë“¤ëŸ¬
      );
      
      ws.connect({
        language: 'auto',
        useWhisper: false,  // ì˜µì…˜ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
        sampleRate: 16000
      });
      
      setWsService(ws);

      // 3. ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ (ê¸°ì¡´ ì½”ë“œì™€ ìœ ì‚¬í•˜ì§€ë§Œ ws.sendAudioDataë¡œ ì „ì†¡)
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = inputCtx.createMediaStreamSource(stream);
      
      const processor = inputCtx.createScriptProcessor(4096, 1, 1);
      processor.onaudioprocess = (e) => {
        if (isMuted || !ws) return;
        const inputData = e.inputBuffer.getChannelData(0);
        const pcmBlob = createPcmBlob(inputData);
        
        // Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ì†¡
        const reader = new FileReader();
        reader.onloadend = () => {
          const base64 = reader.result?.toString().split(',')[1];
          if (base64) {
            ws.sendAudioData(base64, Date.now());
          }
        };
        reader.readAsDataURL(pcmBlob);
      };
      
      source.connect(processor);
      processor.connect(inputCtx.destination);
      
      setConnectionState(ConnectionState.CONNECTED);
      
    } catch (e: any) {
      console.error(e);
      setError(e.message || "Failed to connect");
      setConnectionState(ConnectionState.ERROR);
      stopAudio();
    }
  };

  // WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
  const handleWebSocketMessage = useCallback((message: any) => {
    switch (message.type) {
      case 'connected':
        console.log('Session ID:', message.sessionId);
        break;
        
      case 'input_transcription':
        if (message.isFinal) {
          // ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ messagesì— ì¶”ê°€
        } else {
          // ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
          setStreamingUserText(message.text);
        }
        break;
        
      case 'output_transcription':
        if (message.isFinal) {
          // ìµœì¢… í…ìŠ¤íŠ¸ë¥¼ messagesì— ì¶”ê°€
        } else {
          setStreamingModelText(message.text);
        }
        break;
        
      case 'audio_response':
        // ì˜¤ë””ì˜¤ ì¬ìƒ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)
        const audioData = message.data;
        if (audioData && outputAudioContextRef.current && outputGainRef.current) {
          const ctx = outputAudioContextRef.current;
          decodeAudioData(base64ToArrayBuffer(audioData), ctx)
            .then(buffer => {
              const source = ctx.createBufferSource();
              source.buffer = buffer;
              source.connect(outputGainRef.current!);
              source.start(nextStartTimeRef.current);
              nextStartTimeRef.current += buffer.duration;
            });
        }
        break;
        
      case 'turn_complete':
        // í„´ ì™„ë£Œ ì²˜ë¦¬
        break;
        
      case 'error':
        setError(message.message);
        break;
    }
  }, []);

  const handleWebSocketError = useCallback((error: any) => {
    setError("WebSocket connection error");
    setConnectionState(ConnectionState.ERROR);
  }, []);

  return (
    // ... (ê¸°ì¡´ UI ì½”ë“œ ìœ ì§€)
  );
}
```

### 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

**.env.local (ë¡œì»¬ ê°œë°œìš©)**
```env
VITE_WS_URL=ws://localhost:8000/ws
```

**.env.production (Netlify ë°°í¬ìš©)**
```env
VITE_WS_URL=wss://your-render-app.onrender.com/ws
```

**netlify.toml**
```toml
[build]
  command = "npm run build"
  publish = "dist"

[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200
```

---

## ë°±ì—”ë“œ êµ¬ì¡°

### í”„ë¡œì íŠ¸ êµ¬ì¡°
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI ì•± ì§„ì…ì 
â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ handler.py          # WebSocket í•¸ë“¤ëŸ¬
â”‚   â”‚   â””â”€â”€ protocol.py         # ë©”ì‹œì§€ í”„ë¡œí† ì½œ ì •ì˜
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gemini_service.py   # Gemini API í†µí•©
â”‚   â”‚   â””â”€â”€ whisper_service.py  # Whisper STT í†µí•©
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ messages.py         # Pydantic ëª¨ë¸
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ audio.py            # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ìœ í‹¸
â”œâ”€â”€ rust_stt/                   # Rust STT ëª¨ë“ˆ
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ lib.rs
â”‚   â””â”€â”€ models/                 # Whisper ëª¨ë¸ íŒŒì¼
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ render.yaml                 # Render.com ë°°í¬ ì„¤ì •
```

### 1. main.py

```python
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import os

from app.websocket.handler import WebSocketHandler

load_dotenv()

app = FastAPI(title="Gemini Live Interpreter Backend")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",  # Vite ë¡œì»¬ ê°œë°œ
        "https://your-netlify-app.netlify.app"  # Netlify ë°°í¬
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    handler = WebSocketHandler(websocket)
    await handler.handle()

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
```

### 2. websocket/handler.py

```python
from fastapi import WebSocket, WebSocketDisconnect
import json
import logging
from typing import Optional

from ..services.gemini_service import GeminiService
from ..services.whisper_service import WhisperService
from ..models.messages import InitMessage, AudioMessage

logger = logging.getLogger(__name__)

class WebSocketHandler:
    def __init__(self, websocket: WebSocket):
        self.websocket = websocket
        self.gemini_service: Optional[GeminiService] = None
        self.whisper_service: Optional[WhisperService] = None
        self.session_id: str = ""
        self.use_whisper: bool = False
    
    async def handle(self):
        await self.websocket.accept()
        
        try:
            while True:
                # ë©”ì‹œì§€ ìˆ˜ì‹ 
                data = await self.websocket.receive_text()
                message = json.loads(data)
                
                msg_type = message.get("type")
                
                if msg_type == "init":
                    await self.handle_init(message)
                elif msg_type == "audio":
                    await self.handle_audio(message)
                elif msg_type == "interrupt":
                    await self.handle_interrupt()
                elif msg_type == "close":
                    break
                    
        except WebSocketDisconnect:
            logger.info(f"Client disconnected: {self.session_id}")
        except Exception as e:
            logger.error(f"Error in WebSocket handler: {e}")
            await self.send_error(str(e))
        finally:
            await self.cleanup()
    
    async def handle_init(self, message: dict):
        """ì´ˆê¸°í™” ë©”ì‹œì§€ ì²˜ë¦¬"""
        config = message.get("config", {})
        self.use_whisper = config.get("useWhisper", False)
        
        # ì„¸ì…˜ ID ìƒì„±
        import uuid
        self.session_id = str(uuid.uuid4())
        
        # Gemini ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.gemini_service = GeminiService(
            on_input_transcription=self.on_input_transcription,
            on_output_transcription=self.on_output_transcription,
            on_audio_response=self.on_audio_response,
            on_turn_complete=self.on_turn_complete
        )
        await self.gemini_service.connect()
        
        # Whisper ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
        if self.use_whisper:
            self.whisper_service = WhisperService()
        
        # ì—°ê²° í™•ì¸ ì „ì†¡
        await self.websocket.send_json({
            "type": "connected",
            "sessionId": self.session_id
        })
    
    async def handle_audio(self, message: dict):
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬"""
        audio_data = message.get("data")
        timestamp = message.get("timestamp")
        
        if self.use_whisper and self.whisper_service:
            # Whisper STT ì‚¬ìš©
            transcription = await self.whisper_service.transcribe(audio_data)
            if transcription:
                await self.gemini_service.send_text(transcription)
        else:
            # Gemini Native Audio ì‚¬ìš©
            await self.gemini_service.send_audio(audio_data)
    
    async def handle_interrupt(self):
        """ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬"""
        if self.gemini_service:
            await self.gemini_service.interrupt()
    
    # ì½œë°± ë©”ì„œë“œë“¤
    async def on_input_transcription(self, text: str, is_final: bool):
        await self.websocket.send_json({
            "type": "input_transcription",
            "text": text,
            "isFinal": is_final
        })
    
    async def on_output_transcription(self, text: str, is_final: bool):
        await self.websocket.send_json({
            "type": "output_transcription",
            "text": text,
            "isFinal": is_final
        })
    
    async def on_audio_response(self, audio_data: str, sample_rate: int):
        await self.websocket.send_json({
            "type": "audio_response",
            "data": audio_data,
            "sampleRate": sample_rate
        })
    
    async def on_turn_complete(self, input_text: str, output_text: str):
        await self.websocket.send_json({
            "type": "turn_complete",
            "inputText": input_text,
            "outputText": output_text
        })
    
    async def send_error(self, message: str, code: str = "UNKNOWN"):
        await self.websocket.send_json({
            "type": "error",
            "message": message,
            "code": code
        })
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.gemini_service:
            await self.gemini_service.disconnect()
        if self.whisper_service:
            self.whisper_service.cleanup()
```

### 3. services/gemini_service.py

```python
import os
import asyncio
import base64
from typing import Callable, Awaitable
import logging

import google.generativeai as genai
from google.generativeai.types import LiveServerMessage

logger = logging.getLogger(__name__)

SYSTEM_INSTRUCTION = """You are an ultra-fast, bidirectional simultaneous interpreter for a voice-to-voice translation system.

### CORE INSTRUCTIONS:
1. **Auto-Detection:**
   - If the input is primarily KOREAN, translate to ENGLISH.
   - If the input is primarily ENGLISH, translate to KOREAN.

2. **Zero-Latency Output:**
   - Output **ONLY** the translated text/speech.
   - **STRICTLY FORBIDDEN:** Do not output markdown, prefixes, explanations.
   - Start the translation immediately.

3. **TTS Optimization (Spoken Style):**
   - Translate into natural **spoken language**.
   - Use punctuation strategically to create natural breathing pauses.
"""

MODEL_NAME = 'gemini-2.5-flash-native-audio-preview-09-2025'

class GeminiService:
    def __init__(
        self,
        on_input_transcription: Callable[[str, bool], Awaitable[None]],
        on_output_transcription: Callable[[str, bool], Awaitable[None]],
        on_audio_response: Callable[[str, int], Awaitable[None]],
        on_turn_complete: Callable[[str, str], Awaitable[None]]
    ):
        self.on_input_transcription = on_input_transcription
        self.on_output_transcription = on_output_transcription
        self.on_audio_response = on_audio_response
        self.on_turn_complete = on_turn_complete
        
        self.session = None
        self.current_input_text = ""
        self.current_output_text = ""
        
        # API í‚¤ ì„¤ì •
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment")
        genai.configure(api_key=api_key)
    
    async def connect(self):
        """Gemini Live ì„¸ì…˜ ì—°ê²°"""
        config = {
            "model": MODEL_NAME,
            "config": {
                "response_modalities": ["AUDIO"],
                "system_instruction": SYSTEM_INSTRUCTION,
                "speech_config": {
                    "voice_config": {"prebuilt_voice_config": {"voice_name": "Zephyr"}}
                },
                "input_audio_transcription": {},
                "output_audio_transcription": {},
            }
        }
        
        try:
            client = genai.Client()
            self.session = await client.live.connect(**config)
            
            # ë©”ì‹œì§€ ìˆ˜ì‹  íƒœìŠ¤í¬ ì‹œì‘
            asyncio.create_task(self._receive_messages())
            
            logger.info("Gemini Live session connected")
        except Exception as e:
            logger.error(f"Failed to connect to Gemini: {e}")
            raise
    
    async def send_audio(self, base64_audio: str):
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡"""
        if not self.session:
            raise RuntimeError("Session not connected")
        
        try:
            audio_bytes = base64.b64decode(base64_audio)
            await self.session.send_realtime_input({"media": audio_bytes})
        except Exception as e:
            logger.error(f"Error sending audio: {e}")
    
    async def send_text(self, text: str):
        """í…ìŠ¤íŠ¸ ì „ì†¡ (Whisper ì‚¬ìš© ì‹œ)"""
        if not self.session:
            raise RuntimeError("Session not connected")
        
        try:
            await self.session.send(text)
        except Exception as e:
            logger.error(f"Error sending text: {e}")
    
    async def interrupt(self):
        """ì¸í„°ëŸ½íŠ¸ ì‹ í˜¸ ì „ì†¡"""
        # Gemini Live APIì— ì¸í„°ëŸ½íŠ¸ ë©”ì„œë“œê°€ ìˆë‹¤ë©´ ì‚¬ìš©
        # ì—†ë‹¤ë©´ ìƒˆ ì„¸ì…˜ìœ¼ë¡œ ì¬ì—°ê²°
        self.current_output_text = ""
    
    async def disconnect(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        if self.session:
            # ì„¸ì…˜ ì¢…ë£Œ ë¡œì§
            self.session = None
    
    async def _receive_messages(self):
        """Geminië¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ """
        try:
            async for message in self.session:
                await self._handle_message(message)
        except Exception as e:
            logger.error(f"Error receiving messages: {e}")
    
    async def _handle_message(self, message: LiveServerMessage):
        """Gemini ë©”ì‹œì§€ ì²˜ë¦¬"""
        # ì…ë ¥ ì „ì‚¬
        input_tx = message.server_content.input_transcription.text if message.server_content.input_transcription else None
        if input_tx:
            self.current_input_text += input_tx
            await self.on_input_transcription(self.current_input_text, False)
        
        # ì¶œë ¥ ì „ì‚¬
        output_tx = message.server_content.output_transcription.text if message.server_content.output_transcription else None
        if output_tx:
            self.current_output_text += output_tx
            await self.on_output_transcription(self.current_output_text, False)
        
        # ì˜¤ë””ì˜¤ ì‘ë‹µ
        if message.server_content.model_turn and message.server_content.model_turn.parts:
            for part in message.server_content.model_turn.parts:
                if part.inline_data and part.inline_data.data:
                    audio_data = part.inline_data.data
                    # base64 ì¸ì½”ë”©ëœ PCM ë°ì´í„°
                    await self.on_audio_response(audio_data, 24000)
        
        # í„´ ì™„ë£Œ
        if message.server_content.turn_complete:
            await self.on_input_transcription(self.current_input_text, True)
            await self.on_output_transcription(self.current_output_text, True)
            await self.on_turn_complete(self.current_input_text, self.current_output_text)
            
            # ë¦¬ì…‹
            self.current_input_text = ""
            self.current_output_text = ""
        
        # ì¸í„°ëŸ½íŠ¸
        if message.server_content.interrupted:
            self.current_output_text = ""
```

### 4. services/whisper_service.py

```python
import base64
import numpy as np
import logging
from typing import Optional

# Rust ëª¨ë“ˆ import
try:
    import whisper_stt
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    logging.warning("Whisper STT module not available")

logger = logging.getLogger(__name__)

class WhisperService:
    def __init__(self, model_path: str = "./rust_stt/models/ggml-base.bin"):
        if not WHISPER_AVAILABLE:
            raise RuntimeError("Whisper STT module not installed")
        
        self.model = whisper_stt.WhisperModel(model_path)
        logger.info(f"Whisper model loaded from {model_path}")
    
    async def transcribe(self, base64_audio: str) -> Optional[str]:
        """ì˜¤ë””ì˜¤ ì „ì‚¬"""
        try:
            # base64 ë””ì½”ë”©
            audio_bytes = base64.b64decode(base64_audio)
            
            # PCM ë°ì´í„°ë¥¼ numpy arrayë¡œ ë³€í™˜
            audio_array = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
            
            # Whisper ì¶”ë¡  (Rust ëª¨ë“ˆ í˜¸ì¶œ)
            result = self.model.transcribe(audio_array.tolist())
            
            return result.get("text", "")
        except Exception as e:
            logger.error(f"Whisper transcription error: {e}")
            return None
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if hasattr(self, 'model'):
            del self.model
```

---

## Rust + Whisper í†µí•©

### 1. Rust ëª¨ë“ˆ êµ¬ì¡°

**rust_stt/src/lib.rs**
```rust
use pyo3::prelude::*;
use pyo3::types::PyDict;
use whisper_rs::{WhisperContext, WhisperContextParameters, FullParams, SamplingStrategy};
use std::path::Path;

#[pyclass]
struct WhisperModel {
    ctx: WhisperContext,
}

#[pymethods]
impl WhisperModel {
    #[new]
    fn new(model_path: String) -> PyResult<Self> {
        let path = Path::new(&model_path);
        let ctx = WhisperContext::new_with_params(
            path.to_str().unwrap(),
            WhisperContextParameters::default(),
        )
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("{:?}", e)))?;
        
        Ok(WhisperModel { ctx })
    }

    fn transcribe(&mut self, audio_data: Vec<f32>, py: Python) -> PyResult<PyObject> {
        let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });
        params.set_language(Some("auto"));
        params.set_translate(false);
        params.set_print_progress(false);
        params.set_print_special(false);
        params.set_print_realtime(false);

        let mut state = self.ctx.create_state()
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("{:?}", e)))?;

        state.full(params, &audio_data)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("{:?}", e)))?;

        let num_segments = state.full_n_segments()
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("{:?}", e)))?;

        let mut full_text = String::new();
        for i in 0..num_segments {
            let segment = state.full_get_segment_text(i)
                .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("{:?}", e)))?;
            full_text.push_str(&segment);
        }

        let result = PyDict::new_bound(py);
        result.set_item("text", full_text)?;
        
        Ok(result.into())
    }
}

#[pymodule]
fn whisper_stt(_py: Python, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_class::<WhisperModel>()?;
    Ok(())
}
```

### 2. ë¹Œë“œ ë° ì„¤ì¹˜

**ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸: `build_rust.sh`**
```bash
#!/bin/bash

cd rust_stt

# Rust ë¹Œë“œ
cargo build --release

# Python íŒ¨í‚¤ì§€ë¡œ ë³µì‚¬
cp target/release/libwhisper_stt.so ../app/whisper_stt.so
# ë˜ëŠ” macOSì˜ ê²½ìš°:
# cp target/release/libwhisper_stt.dylib ../app/whisper_stt.so
# Windowsì˜ ê²½ìš°:
# cp target/release/whisper_stt.dll ../app/whisper_stt.pyd

echo "Rust module built successfully"
```

### 3. Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
#!/bin/bash
# download_models.sh

mkdir -p rust_stt/models
cd rust_stt/models

# Base ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (74MB)
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin

# ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸:
# Small (466MB): ggml-small.bin
# Medium (1.5GB): ggml-medium.bin
# Large (2.9GB): ggml-large-v3.bin

echo "Whisper models downloaded"
```

---

## ë°°í¬ ì „ëµ

### Netlify (í”„ë¡ íŠ¸ì—”ë“œ)

**1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •**
- Netlify Dashboard â†’ Site settings â†’ Environment variables
- `VITE_WS_URL`: `wss://your-backend.onrender.com/ws`

**2. netlify.toml**
```toml
[build]
  command = "npm run build"
  publish = "dist"
  
[build.environment]
  NODE_VERSION = "20"

[[redirects]]
  from = "/*"
  to = "/index.html"
  status = 200

[[headers]]
  for = "/*"
  [headers.values]
    X-Frame-Options = "DENY"
    X-Content-Type-Options = "nosniff"
```

**3. ë°°í¬ ëª…ë ¹**
```bash
# ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸
npm run build
npm run preview

# Git pushë¡œ ìë™ ë°°í¬
git push origin main
```

### Render.com (ë°±ì—”ë“œ)

**1. render.yaml**
```yaml
services:
  - type: web
    name: gemini-interpreter-backend
    env: python
    region: oregon
    plan: starter  # ë˜ëŠ” standard
    buildCommand: |
      pip install -r requirements.txt
      chmod +x build_rust.sh
      ./build_rust.sh
      chmod +x download_models.sh
      ./download_models.sh
    startCommand: "uvicorn app.main:app --host 0.0.0.0 --port $PORT"
    envVars:
      - key: PYTHON_VERSION
        value: 3.11.0
      - key: GEMINI_API_KEY
        sync: false  # Render Dashboardì—ì„œ ì„¤ì •
      - key: PORT
        value: 8000
```

**2. Dockerfile (ì„ íƒì‚¬í•­ - ì»¤ìŠ¤í…€ ë¹Œë“œ)**
```dockerfile
FROM rust:1.75 as rust-builder

WORKDIR /app
COPY rust_stt/ ./rust_stt/
WORKDIR /app/rust_stt
RUN cargo build --release

FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Rust ëª¨ë“ˆ ë³µì‚¬
COPY --from=rust-builder /app/rust_stt/target/release/libwhisper_stt.so /app/app/whisper_stt.so

# ì•± ì½”ë“œ ë³µì‚¬
COPY app/ ./app/
COPY download_models.sh .
RUN chmod +x download_models.sh && ./download_models.sh

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì‹¤í–‰
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •**
- Render Dashboard â†’ Environment â†’ Add Environment Variable
- `GEMINI_API_KEY`: (Gemini API í‚¤)
- `WHISPER_MODEL_PATH`: `./rust_stt/models/ggml-base.bin`

**4. ë°°í¬**
```bash
# Renderì— Git ì—°ê²° í›„ ìë™ ë°°í¬
# ë˜ëŠ” Render CLI ì‚¬ìš©
render deploy
```

---

## êµ¬í˜„ ë‹¨ê³„

### Phase 1: ê¸°ë³¸ WebSocket í†µì‹  êµ¬ì¶• (1ì£¼)

**í”„ë¡ íŠ¸ì—”ë“œ:**
- [ ] WebSocketService í´ë˜ìŠ¤ êµ¬í˜„
- [ ] App.tsxì—ì„œ Gemini ì§ì ‘ í˜¸ì¶œ ì œê±°
- [ ] WebSocket ì—°ê²° ë° ë©”ì‹œì§€ ì†¡ìˆ˜ì‹  ë¡œì§ ì¶”ê°€
- [ ] ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •

**ë°±ì—”ë“œ:**
- [ ] FastAPI í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
- [ ] WebSocket ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] Gemini API ê¸°ë³¸ í†µí•© (Native Audio)
- [ ] ë©”ì‹œì§€ í”„ë¡œí† ì½œ êµ¬í˜„
- [ ] ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì„œë²„ ì‹¤í–‰

**í…ŒìŠ¤íŠ¸:**
```bash
# ë°±ì—”ë“œ ì‹¤í–‰
cd backend
python -m app.main

# í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰
npm run dev
```

### Phase 2: Rust Whisper STT í†µí•© (1-2ì£¼)

**Rust ëª¨ë“ˆ:**
- [ ] Rust í”„ë¡œì íŠ¸ ìƒì„± ë° whisper-rs ì„¤ì •
- [ ] PyO3 ë°”ì¸ë”© êµ¬í˜„
- [ ] Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ í…ŒìŠ¤íŠ¸
- [ ] Pythonì—ì„œ Rust ëª¨ë“ˆ í˜¸ì¶œ í…ŒìŠ¤íŠ¸

**ë°±ì—”ë“œ:**
- [ ] WhisperService í´ë˜ìŠ¤ êµ¬í˜„
- [ ] WebSocketHandlerì— Whisper ì˜µì…˜ ì¶”ê°€
- [ ] Whisper STT + Gemini Text API í†µí•©

**í”„ë¡ íŠ¸ì—”ë“œ:**
- [ ] UIì— "Use Whisper STT" ì˜µì…˜ ì¶”ê°€
- [ ] ì„¤ì • ë©”ë‰´ êµ¬í˜„

### Phase 3: ë°°í¬ ë° ìµœì í™” (1ì£¼)

**í”„ë¡ íŠ¸ì—”ë“œ ë°°í¬:**
- [ ] Netlify ê³„ì • ìƒì„± ë° í”„ë¡œì íŠ¸ ì—°ê²°
- [ ] í™˜ê²½ë³€ìˆ˜ ì„¤ì •
- [ ] ë¹Œë“œ ë° ë°°í¬ í…ŒìŠ¤íŠ¸
- [ ] ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì„¤ì • (ì„ íƒ)

**ë°±ì—”ë“œ ë°°í¬:**
- [ ] Render.com ê³„ì • ìƒì„± ë° í”„ë¡œì íŠ¸ ì—°ê²°
- [ ] render.yaml ë˜ëŠ” Dockerfile ì„¤ì •
- [ ] Rust ë¹Œë“œ íŒŒì´í”„ë¼ì¸ ì„¤ì •
- [ ] Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìë™í™”
- [ ] í™˜ê²½ë³€ìˆ˜ ë° ì‹œí¬ë¦¿ ì„¤ì •
- [ ] ë°°í¬ í…ŒìŠ¤íŠ¸

**ìµœì í™”:**
- [ ] WebSocket ì¬ì—°ê²° ë¡œì§ ê°•í™”
- [ ] ì˜¤ë””ì˜¤ ë²„í¼ë§ ìµœì í™”
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ 
- [ ] ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì¶”ê°€

### Phase 4: í…ŒìŠ¤íŠ¸ ë° ë¬¸ì„œí™” (ì§€ì†ì )

- [ ] E2E í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±
- [ ] API ë¬¸ì„œ ìƒì„± (FastAPI ìë™ ìƒì„±)
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

---

## í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ

### 1. í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìš© í”„ë¡¬í”„íŠ¸

#### WebSocket í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
```
í”„ë¡¬í”„íŠ¸:
gemini-live-interpreter_v2 í”„ë¡œì íŠ¸ì—ì„œ WebSocket í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤ë¥¼ êµ¬í˜„í•´ì¤˜.

ìš”êµ¬ì‚¬í•­:
1. src/services/WebSocketService.ts íŒŒì¼ ìƒì„±
2. ì—°ê²°, ì¬ì—°ê²°, ë©”ì‹œì§€ ì†¡ìˆ˜ì‹  ê¸°ëŠ¥
3. íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ íƒ€ì… ì •ì˜ í¬í•¨
4. ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œê¹…
5. ì¬ì—°ê²° ë¡œì§ (ìµœëŒ€ 5íšŒ ì‹œë„, ì§€ìˆ˜ ë°±ì˜¤í”„)

ë©”ì‹œì§€ íƒ€ì…:
- init: ì´ˆê¸°í™”
- audio: ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
- interrupt: ì¸í„°ëŸ½íŠ¸
- close: ì—°ê²° ì¢…ë£Œ

ì°¸ê³ : project-analysis_v2.mdì˜ "WebSocket ë©”ì‹œì§€ í”„ë¡œí† ì½œ" ì„¹ì…˜ ì°¸ì¡°
```

#### App.tsx ë¦¬íŒ©í† ë§
```
í”„ë¡¬í”„íŠ¸:
App.tsxë¥¼ ìˆ˜ì •í•˜ì—¬ Gemini API ì§ì ‘ í˜¸ì¶œ ëŒ€ì‹  WebSocketServiceë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½í•´ì¤˜.

ë³€ê²½ì‚¬í•­:
1. @google/genai import ì œê±°
2. WebSocketService import ì¶”ê°€
3. connectToGemini í•¨ìˆ˜ë¥¼ connectToBackendë¡œ ë³€ê²½
4. WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ êµ¬í˜„
5. ê¸°ì¡´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë¡œì§ì€ ìµœëŒ€í•œ ìœ ì§€
6. í™˜ê²½ë³€ìˆ˜ VITE_WS_URL ì‚¬ìš©

ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€:
- ë§ˆì´í¬ ì…ë ¥ ë° ì‹œê°í™”
- ì˜¤ë””ì˜¤ ì¶œë ¥ ë° ì¬ìƒ
- ì „ì‚¬ í…ìŠ¤íŠ¸ í‘œì‹œ
- UI/UX

ì°¸ê³ : project-analysis_v2.mdì˜ "í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½ì‚¬í•­" ì„¹ì…˜
```

### 2. ë°±ì—”ë“œ ê°œë°œìš© í”„ë¡¬í”„íŠ¸

#### FastAPI ê¸°ë³¸ êµ¬ì¡°
```
í”„ë¡¬í”„íŠ¸:
FastAPIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìŒì„± í†µì—­ ë°±ì—”ë“œë¥¼ êµ¬ì¶•í•´ì¤˜.

í”„ë¡œì íŠ¸ êµ¬ì¡°:
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”œâ”€â”€ handler.py
â”‚   â”‚   â””â”€â”€ protocol.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ gemini_service.py
â”‚   â”‚   â””â”€â”€ whisper_service.py
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ messages.py
â””â”€â”€ requirements.txt

ìš”êµ¬ì‚¬í•­:
1. WebSocket ì—”ë“œí¬ì¸íŠ¸ (/ws) êµ¬í˜„
2. CORS ì„¤ì • (Netlify ë„ë©”ì¸ í—ˆìš©)
3. í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (/health)
4. í™˜ê²½ë³€ìˆ˜ë¡œ GEMINI_API_KEY ê´€ë¦¬
5. ë¹„ë™ê¸° ì²˜ë¦¬ (asyncio)

ì°¸ê³ : project-analysis_v2.mdì˜ "ë°±ì—”ë“œ êµ¬ì¡°" ì„¹ì…˜
```

#### Gemini ì„œë¹„ìŠ¤ í†µí•©
```
í”„ë¡¬í”„íŠ¸:
Gemini Live APIë¥¼ FastAPI ë°±ì—”ë“œì— í†µí•©í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•´ì¤˜.

íŒŒì¼: app/services/gemini_service.py

ê¸°ëŠ¥:
1. Gemini Live ì„¸ì…˜ ì—°ê²° ë° ê´€ë¦¬
2. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì…ë ¥ ì „ì†¡
3. ì…ë ¥/ì¶œë ¥ ì „ì‚¬ í…ìŠ¤íŠ¸ ì½œë°±
4. ì˜¤ë””ì˜¤ ì‘ë‹µ ì½œë°±
5. í„´ ì™„ë£Œ ë° ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬
6. ë¹„ë™ê¸° ë©”ì‹œì§€ ìˆ˜ì‹  ë£¨í”„

ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:
- í•œâ†”ì˜ ìë™ ê°ì§€ ë²ˆì—­
- ìŒì„± ìµœì í™” ì¶œë ¥
- ì €ì§€ì—°

ì°¸ê³ : ê¸°ì¡´ App.tsxì˜ Gemini ì—°ê²° ë¡œì§ ë° SYSTEM_INSTRUCTION
```

### 3. Rust + Whisper í†µí•©ìš© í”„ë¡¬í”„íŠ¸

#### Rust ëª¨ë“ˆ ê¸°ë³¸ êµ¬ì¡°
```
í”„ë¡¬í”„íŠ¸:
OpenAI Whisperë¥¼ Rustë¡œ êµ¬í˜„í•˜ì—¬ Pythonì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆì„ ë§Œë“¤ì–´ì¤˜.

ê¸°ìˆ  ìŠ¤íƒ:
- whisper-rs (whisper.cpp Rust ë°”ì¸ë”©)
- PyO3 (Python FFI)

íŒŒì¼: rust_stt/src/lib.rs

ê¸°ëŠ¥:
1. Whisper ëª¨ë¸ ë¡œë“œ (GGML í¬ë§·)
2. Float32 ì˜¤ë””ì˜¤ ë°°ì—´ì„ ë°›ì•„ ì „ì‚¬
3. Pythonì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ì¸í„°í˜ì´ìŠ¤
4. ì—ëŸ¬ í•¸ë“¤ë§

ì‚¬ìš© ì˜ˆ:
```python
import whisper_stt
model = whisper_stt.WhisperModel("path/to/model.bin")
result = model.transcribe(audio_data)  # audio_data: List[float]
print(result["text"])
```

ì°¸ê³ : project-analysis_v2.mdì˜ "Rust + Whisper í†µí•©" ì„¹ì…˜
```

#### Pythonì—ì„œ Rust ëª¨ë“ˆ ì‚¬ìš©
```
í”„ë¡¬í”„íŠ¸:
Rustë¡œ ë¹Œë“œí•œ Whisper STT ëª¨ë“ˆì„ Python ë°±ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•´ì¤˜.

íŒŒì¼: app/services/whisper_service.py

ê¸°ëŠ¥:
1. Rust ëª¨ë“ˆ import ë° ëª¨ë¸ ë¡œë“œ
2. base64 ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ numpy arrayë¡œ ë³€í™˜
3. Whisper ì¶”ë¡  ì‹¤í–‰
4. ì „ì‚¬ í…ìŠ¤íŠ¸ ë°˜í™˜
5. ë¹„ë™ê¸° ì²˜ë¦¬ (asyncio)
6. ì—ëŸ¬ í•¸ë“¤ë§ ë° fallback

ì°¸ê³ : project-analysis_v2.mdì˜ "services/whisper_service.py" ì„¹ì…˜
```

### 4. ë°°í¬ìš© í”„ë¡¬í”„íŠ¸

#### Netlify ë°°í¬ ì„¤ì •
```
í”„ë¡¬í”„íŠ¸:
React + Vite í”„ë¡œì íŠ¸ë¥¼ Netlifyì— ë°°í¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•´ì¤˜.

íŒŒì¼: netlify.toml

ì„¤ì • í•­ëª©:
1. ë¹Œë“œ ëª…ë ¹: npm run build
2. í¼ë¸”ë¦¬ì‹œ ë””ë ‰í† ë¦¬: dist
3. SPA ë¦¬ë‹¤ì´ë ‰íŠ¸ ì„¤ì •
4. í™˜ê²½ë³€ìˆ˜ (VITE_WS_URL)
5. ë³´ì•ˆ í—¤ë”

ë°°í¬ í™˜ê²½ë³€ìˆ˜ (Netlify Dashboardì—ì„œ ì„¤ì •):
- VITE_WS_URL: wss://your-backend.onrender.com/ws

ì°¸ê³ : project-analysis_v2.mdì˜ "Netlify ë°°í¬ ì „ëµ" ì„¹ì…˜
```

#### Render.com ë°°í¬ ì„¤ì •
```
í”„ë¡¬í”„íŠ¸:
FastAPI + Rust ë°±ì—”ë“œë¥¼ Render.comì— ë°°í¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼ì„ ìƒì„±í•´ì¤˜.

íŒŒì¼: render.yaml

ì„¤ì • í•­ëª©:
1. Python í™˜ê²½ (3.11)
2. ë¹Œë“œ ëª…ë ¹:
   - pip install
   - Rust ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
   - Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
3. ì‹œì‘ ëª…ë ¹: uvicorn
4. í™˜ê²½ë³€ìˆ˜:
   - GEMINI_API_KEY (ì‹œí¬ë¦¿)
   - WHISPER_MODEL_PATH
5. ë¦¬ì „ ë° í”Œëœ ì„¤ì •

ì¶”ê°€ íŒŒì¼:
- build_rust.sh: Rust ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
- download_models.sh: Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

ì°¸ê³ : project-analysis_v2.mdì˜ "Render.com ë°°í¬ ì „ëµ" ì„¹ì…˜
```

### 5. í†µí•© í…ŒìŠ¤íŠ¸ìš© í”„ë¡¬í”„íŠ¸

#### E2E í…ŒìŠ¤íŠ¸
```
í”„ë¡¬í”„íŠ¸:
í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ í†µì‹ í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” E2E í…ŒìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì¤˜.

í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
1. WebSocket ì—°ê²° ì„±ê³µ
2. ì´ˆê¸°í™” ë©”ì‹œì§€ ì†¡ìˆ˜ì‹ 
3. ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
4. ì „ì‚¬ í…ìŠ¤íŠ¸ ìˆ˜ì‹ 
5. ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹ 
6. ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬
7. ì—°ê²° ì¢…ë£Œ

ë„êµ¬:
- í”„ë¡ íŠ¸ì—”ë“œ: Vitest + Testing Library
- ë°±ì—”ë“œ: pytest + pytest-asyncio

ì°¸ê³ : ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  Mock ì‚¬ìš©
```

### 6. ìµœì í™”ìš© í”„ë¡¬í”„íŠ¸

#### ì„±ëŠ¥ ìµœì í™”
```
í”„ë¡¬í”„íŠ¸:
ì‹¤ì‹œê°„ ìŒì„± í†µì—­ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ìµœì í™”í•´ì¤˜.

ìµœì í™” ì˜ì—­:
1. WebSocket ë©”ì‹œì§€ ì••ì¶• (gzip)
2. ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸° ì¡°ì • (ì§€ì—° vs í’ˆì§ˆ)
3. Whisper ëª¨ë¸ ì„ íƒ (base vs small vs medium)
4. ë°±ì—”ë“œ ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„ 
5. í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë””ì˜¤ ì¬ìƒ í ìµœì í™”

ëª©í‘œ:
- ì—”ë“œíˆ¬ì—”ë“œ ì§€ì—° < 500ms
- CPU ì‚¬ìš©ë¥  < 50%
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 1GB

ì°¸ê³ : project-analysis_v2.md ì „ì²´
```

---

## ì£¼ìš” ê³ ë ¤ì‚¬í•­

### 1. ë³´ì•ˆ
- âœ… API í‚¤ë¥¼ ë°±ì—”ë“œ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬
- âœ… HTTPS/WSS ì‚¬ìš© (Netlify, Render ìë™ ì œê³µ)
- âœ… CORS ì„¤ì •ìœ¼ë¡œ í—ˆìš©ëœ ë„ë©”ì¸ë§Œ ì ‘ê·¼
- âš ï¸ Rate Limiting êµ¬í˜„ ê¶Œì¥
- âš ï¸ ì‚¬ìš©ì ì¸ì¦ (í–¥í›„ ì¶”ê°€ ê³ ë ¤)

### 2. ì„±ëŠ¥
- âœ… Rust Whisperë¡œ STT ì„±ëŠ¥ í–¥ìƒ
- âœ… WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
- âœ… ë¹„ë™ê¸° ì²˜ë¦¬ (FastAPI, asyncio)
- âš ï¸ ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸° ìµœì í™” í•„ìš”
- âš ï¸ Whisper ëª¨ë¸ í¬ê¸° ì„ íƒ (ì†ë„ vs ì •í™•ë„)

### 3. í™•ì¥ì„±
- âœ… í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ ë…ë¦½ ë°°í¬
- âœ… ê° ì„œë¹„ìŠ¤ ë…ë¦½ ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥
- âš ï¸ í–¥í›„ Redis/Kafkaë¡œ ë©”ì‹œì§€ í ì¶”ê°€ ê³ ë ¤
- âš ï¸ ë©€í‹° ì„¸ì…˜ ê´€ë¦¬ (ì„¸ì…˜ DB í•„ìš”)

### 4. ë¹„ìš©
- **Netlify**: ë¬´ë£Œ í”Œëœ (100GB ëŒ€ì—­í­/ì›”)
- **Render.com**: Starter í”Œëœ $7/ì›” (512MB RAM) ë˜ëŠ” ë¬´ë£Œ í”Œëœ
- **Gemini API**: ë¬´ë£Œ í• ë‹¹ëŸ‰ ì œí•œ, ì´ˆê³¼ ì‹œ ìœ ë£Œ
- âš ï¸ Whisper ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ì¦ê°€

### 5. ì œì•½ì‚¬í•­
- **ë¸Œë¼ìš°ì € í˜¸í™˜ì„±**: Web Audio API, WebSocket ì§€ì› í•„ìš”
- **ë„¤íŠ¸ì›Œí¬ ì§€ì—°**: WebSocket RTTì— ì˜í–¥
- **Gemini API ì œí•œ**: Rate limit, ë™ì‹œ ì„¸ì…˜ ìˆ˜
- **Render.com ë¬´ë£Œ í”Œëœ**: Cold start ì‹œê°„ (ë¹„í™œì„± í›„ ì¬ì‹œì‘ ì‹œ ì§€ì—°)

---

## ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´

### ë‹¨ê¸° (1-2ê°œì›”)
1. **ì‚¬ìš©ì ì„¤ì • UI**
   - ì–¸ì–´ ì„ íƒ (auto/ko/en)
   - Whisper on/off í† ê¸€
   - ìŒì„± ì„ íƒ (Zephyr, Puck, Charon)
   - ìŒì§ˆ/ì†ë„ ì¡°ì ˆ

2. **ëŒ€í™” ê¸°ë¡ ì €ì¥**
   - ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ë˜ëŠ” ë°±ì—”ë“œ DB
   - ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥ (TXT, JSON)

3. **ë‹¤êµ­ì–´ ì§€ì›**
   - í•œâ†”ì˜ ì™¸ ì¶”ê°€ ì–¸ì–´ í˜ì–´
   - UI ë‹¤êµ­ì–´í™” (i18n)

### ì¤‘ê¸° (3-6ê°œì›”)
1. **ì‚¬ìš©ì ì¸ì¦**
   - OAuth (Google, GitHub)
   - ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ì œí•œ

2. **í”„ë¦¬ë¯¸ì—„ ê¸°ëŠ¥**
   - ë” í° Whisper ëª¨ë¸ (Medium, Large)
   - ê³ í’ˆì§ˆ TTS ìŒì„±
   - ëŒ€í™” ê¸°ë¡ í´ë¼ìš°ë“œ ì €ì¥

3. **ëª¨ë°”ì¼ ì•±**
   - React Native í¬íŒ…
   - iOS/Android ë„¤ì´í‹°ë¸Œ ê¸°ëŠ¥ í™œìš©

### ì¥ê¸° (6ê°œì›”+)
1. **ë‹¤ìê°„ í†µì—­**
   - ì—¬ëŸ¬ ì‚¬ìš©ì ë™ì‹œ ì°¸ì—¬
   - ì‹¤ì‹œê°„ í†µì—­ ë¸Œë¡œë“œìºìŠ¤íŠ¸

2. **AI ì–´ì‹œìŠ¤í„´íŠ¸ í†µí•©**
   - íšŒì˜ë¡ ìë™ ìƒì„±
   - ìš”ì•½ ë° ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ

3. **ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥**
   - On-premise ë°°í¬ ì˜µì…˜
   - SSO í†µí•©
   - ê°ì‚¬ ë¡œê·¸

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Gemini API - Live Connect](https://ai.google.dev/api/live-connect)
- [FastAPI WebSocket](https://fastapi.tiangolo.com/advanced/websockets/)
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
- [PyO3 User Guide](https://pyo3.rs/)

### ë°°í¬ ê°€ì´ë“œ
- [Netlify Deploy Guide](https://docs.netlify.com/)
- [Render.com Documentation](https://render.com/docs)

### ìƒ˜í”Œ ì½”ë“œ
- [ê¸°ì¡´ í”„ë¡œì íŠ¸ ë¶„ì„](./project-analysis.md)
- [FastAPI WebSocket Example](https://github.com/tiangolo/fastapi/blob/master/docs/en/docs/advanced/websockets.md)

---

## ë²„ì „ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ì‚¬í•­ |
|------|------|----------|
| 2.0.0 | 2024-12 | ë°±ì—”ë“œ ë¶„ë¦¬ ì•„í‚¤í…ì²˜ ì´ˆê¸° ì„¤ê³„ |

---

## ë¼ì´ì„ ìŠ¤ ë° ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” ê¸°ì¡´ gemini-live-interpreterë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°±ì—”ë“œ ë¶„ë¦¬ ì•„í‚¤í…ì²˜ë¡œ ì¬ì„¤ê³„í•œ ë²„ì „ì…ë‹ˆë‹¤.

**ì›ë³¸ í”„ë¡œì íŠ¸**: gemini-live-interpreter (Vite + React + Gemini Live API)
**ì¬ì„¤ê³„ ë²„ì „**: gemini-live-interpreter_v2 (React + Python + Rust ì•„í‚¤í…ì²˜)

---

## ì—°ë½ì²˜ ë° ì§€ì›

ì§ˆë¬¸ì´ë‚˜ ì´ìŠˆê°€ ìˆìœ¼ì‹œë©´ GitHub Issuesë¥¼ ì´ìš©í•´ ì£¼ì„¸ìš”.

**Happy Interpreting! ğŸŒğŸ¤**