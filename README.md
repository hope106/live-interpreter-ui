<div align="center">
<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

# Gemini Live Interpreter

ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŒì„± í†µì—­ ì• í”Œë¦¬ì¼€ì´ì…˜ | Real-time Bidirectional Voice Interpreter

[![React](https://img.shields.io/badge/React-19.2-61dafb?logo=react)](https://react.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.8-3178c6?logo=typescript)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-6.2-646cff?logo=vite)](https://vitejs.dev/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

## ğŸ“– Overview | ê°œìš”

**Gemini Live Interpreter**ëŠ” Googleì˜ Gemini Live APIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ìŒì„± í†µì—­ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ì™€ ì˜ì–´ ê°„ì˜ ì¦‰ê°ì ì¸ ì–‘ë°©í–¥ í†µì—­ì„ ì œê³µí•˜ë©°, ìŒì„± ì…ë ¥ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ìƒëŒ€ ì–¸ì–´ë¡œ ë³€í™˜í•œ í›„ ìŒì„±ê³¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

A real-time voice interpreter web application powered by Google's Gemini Live API. Provides instant bidirectional translation between Korean and English, automatically detecting speech input and converting it to the target language with both audio and text output.

### âœ¨ Key Features | ì£¼ìš” ê¸°ëŠ¥

- ğŸ¤ **ì‹¤ì‹œê°„ ìŒì„± ì…ë ¥** | Real-time Voice Input
  - ë§ˆì´í¬ë¥¼ í†µí•œ ì—°ì† ìŒì„± ìŠ¤íŠ¸ë¦¬ë°
  - Continuous voice streaming via microphone

- ğŸ”Š **ì‹¤ì‹œê°„ ìŒì„± ì¶œë ¥** | Real-time Voice Output
  - AI í†µì—­ ê²°ê³¼ì˜ ì¦‰ê°ì ì¸ ìŒì„± ì¬ìƒ
  - Immediate audio playback of AI translation

- ğŸ“ **ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì „ì‚¬** | Real-time Text Transcription
  - ì‚¬ìš©ì ì…ë ¥ê³¼ AI ì‘ë‹µì˜ í…ìŠ¤íŠ¸ ë³€í™˜ ë° í‘œì‹œ
  - Text conversion and display of user input and AI responses

- ğŸ“Š **ì˜¤ë””ì˜¤ ì‹œê°í™”** | Audio Visualization
  - ì…ë ¥/ì¶œë ¥ ì˜¤ë””ì˜¤ì˜ ì‹¤ì‹œê°„ íŒŒí˜• í‘œì‹œ
  - Real-time waveform display of input/output audio

- ğŸ”„ **ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¬ë°** | Bidirectional Streaming
  - WebSocket ê¸°ë°˜ full-duplex í†µì‹ 
  - Full-duplex communication via WebSocket

- ğŸ¯ **ìŒì„± ìƒíƒœ ì¶”ì ** | Speech State Tracking
  - ë§í•˜ê¸°/ë“£ê¸°/ì²˜ë¦¬ ì¤‘ ìƒíƒœ ì‹¤ì‹œê°„ í‘œì‹œ
  - Real-time display of speaking/listening/processing states

## ğŸ—ï¸ Architecture | ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     gRPC      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  Backend Server â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  Gemini API  â”‚
â”‚   (React)       â”‚  JSON + Base64     â”‚   (FastAPI)     â”‚  Streaming    â”‚   (Google)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     Audio          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ìƒì„¸ ì•„í‚¤í…ì²˜ëŠ” [TECHNICAL_ANALYSIS.md](./TECHNICAL_ANALYSIS.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.**
**For detailed architecture, see [TECHNICAL_ANALYSIS.md](./TECHNICAL_ANALYSIS.md).**

## ğŸš€ Quick Start | ë¹ ë¥¸ ì‹œì‘

### Prerequisites | ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- **Node.js** (v18 ì´ìƒ ê¶Œì¥)
- **Backend Server** ([gemini-live-interpreter backend](../backend))
- **Gemini API Key**

### Installation | ì„¤ì¹˜

1. **Clone the repository | ì €ì¥ì†Œ ë³µì œ**
   ```bash
   git clone <repository-url>
   cd live-interpreter-ui
   ```

2. **Install dependencies | ì˜ì¡´ì„± ì„¤ì¹˜**
   ```bash
   npm install
   ```

3. **Set up environment variables | í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**

   Create `.env.local` file:
   ```env
   VITE_WS_URL=ws://localhost:8000/ws
   VITE_UI_PORT=3000
   ```

4. **Start the backend server | ë°±ì—”ë“œ ì„œë²„ ì‹œì‘**

   Navigate to the backend directory and start the server:
   ```bash
   cd ../backend
   export GEMINI_API_KEY=your_api_key_here
   # Follow backend README for detailed setup
   ```

5. **Run the app | ì•± ì‹¤í–‰**
   ```bash
   npm run dev
   ```

   The app will be available at `http://localhost:3000`

## ğŸ® Usage | ì‚¬ìš© ë°©ë²•

### Starting a Session | ì„¸ì…˜ ì‹œì‘

1. ë¸Œë¼ìš°ì €ì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì—´ê¸° (Open the application in your browser)
2. "Start Session" ë²„íŠ¼ í´ë¦­ (Click the "Start Session" button)
3. ë§ˆì´í¬ ê¶Œí•œ í—ˆìš© (Allow microphone access)
4. í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´ë¡œ ë§í•˜ê¸° ì‹œì‘ (Start speaking in Korean or English)

### Controls | ì œì–´

- **Start/Stop Session**: WebSocket ì—°ê²° ë° ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘/ì¢…ë£Œ
- **Mute/Unmute Mic**: ë§ˆì´í¬ ìŒì†Œê±° í† ê¸€
- **Volume Slider**: AI ì‘ë‹µ ìŒì„± ë³¼ë¥¨ ì¡°ì ˆ (0% ~ 150%)

### Visual Indicators | ì‹œê°ì  í‘œì‹œ

- **Connection Status**: CONNECTED (ì´ˆë¡ìƒ‰), CONNECTING (ë…¸ë€ìƒ‰), DISCONNECTED (íšŒìƒ‰)
- **Speech State**:
  - ğŸ¤ **Speaking** (ë§ì”€í•˜ì„¸ìš”...): ì‚¬ìš©ìê°€ ë§í•  ìˆ˜ ìˆëŠ” ìƒíƒœ
  - ğŸ‘‚ **Silent** (ë“£ê³  ìˆìŠµë‹ˆë‹¤...): AI ì‘ë‹µ ì¤‘ ë˜ëŠ” ëŒ€ê¸° ì¤‘
  - â³ **Processing** (ì²˜ë¦¬ ì¤‘...): AIê°€ ì…ë ¥ì„ ë¶„ì„í•˜ëŠ” ì¤‘

## ğŸ“ Project Structure | í”„ë¡œì íŠ¸ êµ¬ì¡°

```
live-interpreter-ui/
â”œâ”€â”€ App.tsx                      # Main application component
â”œâ”€â”€ index.tsx                    # Entry point
â”œâ”€â”€ types.ts                     # TypeScript type definitions
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Transcript.tsx           # Chat transcript display
â”‚   â”œâ”€â”€ Visualizer.tsx           # Audio waveform visualization
â”‚   â””â”€â”€ SpeechStateIndicator.tsx # Speech state display
â”œâ”€â”€ services/
â”‚   â””â”€â”€ WebSocketService.ts      # WebSocket connection management
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ audioUtils.ts            # Audio processing utilities
â””â”€â”€ TECHNICAL_ANALYSIS.md        # Comprehensive technical documentation
```

## ğŸ› ï¸ Technology Stack | ê¸°ìˆ  ìŠ¤íƒ

### Frontend
- **React 19.2.1**: UI ì»´í¬ë„ŒíŠ¸ ë° ìƒíƒœ ê´€ë¦¬
- **TypeScript 5.8.2**: ì •ì  íƒ€ì… ì‹œìŠ¤í…œ
- **Vite 6.2.0**: ë¹Œë“œ ë„êµ¬ ë° ê°œë°œ ì„œë²„
- **Tailwind CSS**: ìœ í‹¸ë¦¬í‹° ê¸°ë°˜ ìŠ¤íƒ€ì¼ë§
- **lucide-react**: ì•„ì´ì½˜ ë¼ì´ë¸ŒëŸ¬ë¦¬

### Web APIs
- **Web Audio API**: ì˜¤ë””ì˜¤ ì…ì¶œë ¥ ë° ì‹œê°í™”
- **WebSocket API**: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- **Canvas API**: ì˜¤ë””ì˜¤ íŒŒí˜• ë Œë”ë§
- **MediaDevices API**: ë§ˆì´í¬ ì ‘ê·¼

### Backend Integration
- **WebSocket Protocol**: JSON ë©”ì‹œì§€ + Base64 ì¸ì½”ë”© ì˜¤ë””ì˜¤
- **Audio Format**: PCM Int16, 16kHz (input), 24kHz (output)

## ğŸ“Š Communication Protocol | í†µì‹  í”„ë¡œí† ì½œ

### Client â†’ Server Messages

```json
// Initialize session
{
  "type": "init",
  "config": {
    "language": "auto",
    "useWhisper": false,
    "sampleRate": 16000
  }
}

// Audio data (every 256ms)
{
  "type": "audio",
  "data": "base64_encoded_pcm",
  "timestamp": 1234567890123
}
```

### Server â†’ Client Messages

```json
// Input transcription (user speech)
{
  "type": "input_transcription",
  "text": "ì•ˆë…•í•˜ì„¸ìš”",
  "isFinal": true,
  "language": "ko"
}

// Output transcription (AI response)
{
  "type": "output_transcription",
  "text": "Hello",
  "isFinal": true,
  "language": "en"
}

// Audio response (AI voice)
{
  "type": "audio_response",
  "data": "base64_encoded_pcm",
  "sampleRate": 24000
}

// Speech state update
{
  "type": "speech_state",
  "state": "speaking",
  "timestamp": 1234567890123
}
```

**ì „ì²´ í”„ë¡œí† ì½œ ëª…ì„¸ëŠ” [TECHNICAL_ANALYSIS.md](./TECHNICAL_ANALYSIS.md#ë°±ì—”ë“œ-í†µì‹ -í”„ë¡œí† ì½œ)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.**

## ğŸ”§ Configuration | ì„¤ì •

### Environment Variables | í™˜ê²½ ë³€ìˆ˜

| Variable        | Description                    | Default                  |
|-----------------|--------------------------------|--------------------------|
| `VITE_WS_URL`   | WebSocket server URL           | `ws://localhost:8000/ws` |
| `VITE_UI_PORT`  | Development server port        | `3000`                   |

### Audio Settings | ì˜¤ë””ì˜¤ ì„¤ì •

- **Input Sample Rate**: 16kHz (Gemini API requirement)
- **Output Sample Rate**: 24kHz (Gemini API output)
- **Buffer Size**: 4096 samples (~256ms latency)
- **Audio Format**: PCM Int16 (16-bit signed integer)

## ğŸ“š Documentation | ë¬¸ì„œ

- **[TECHNICAL_ANALYSIS.md](./TECHNICAL_ANALYSIS.md)**:
  - ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
  - UI êµ¬ì„± ë° í™”ë©´ êµ¬ì¡° ìƒì„¸ ë¶„ì„
  - ìŒì„± ì „ë‹¬ ë©”ì»¤ë‹ˆì¦˜ (ì…ë ¥/ì¶œë ¥ íë¦„)
  - ë°±ì—”ë“œ í†µì‹  í”„ë¡œí† ì½œ ëª…ì„¸
  - ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ë¶„ì„
  - ë°ì´í„° íë¦„ë„ ë° ìƒíƒœ ì „ì´ë„

## ğŸ› Known Limitations | ì•Œë ¤ì§„ ì œí•œì‚¬í•­

1. **ScriptProcessorNode Deprecation**: í–¥í›„ AudioWorkletìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”
2. **Browser Compatibility**: Safari ë° ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €ì—ì„œ ì¼ë¶€ ì œí•œ
3. **Offline Support**: ì¸í„°ë„· ì—°ê²° í•„ìˆ˜
4. **Long Conversations**: ëŒ€í™” ê¸°ë¡ì´ ê¸¸ì–´ì§ˆ ê²½ìš° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€

## ğŸ—ºï¸ Roadmap | ë¡œë“œë§µ

### Short-term (1-2 weeks)
- [ ] AudioWorklet migration
- [ ] Error message localization (KO/EN)
- [ ] Keyboard shortcuts (Space: Mute, Esc: Disconnect)

### Mid-term (1-2 months)
- [ ] Conversation history save/load
- [ ] User settings (volume, language preferences)
- [ ] PWA support (offline detection, installable)
- [ ] Voice Activity Detection (VAD)

### Long-term (3+ months)
- [ ] Multi-language pair support
- [ ] Conversation export (TXT, PDF)
- [ ] Real-time subtitle overlay
- [ ] AI response interruption

## ğŸ“„ License | ë¼ì´ì„ ìŠ¤

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support | ì§€ì›

For issues and questions:
- ğŸ› [GitHub Issues](../../issues)

---

<div align="center">

**Built with â¤ï¸ using React, TypeScript, and Gemini Live API**

</div>
